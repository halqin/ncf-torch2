{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d3cbac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import config\n",
    "import data_process.neg_sample as ng_sample\n",
    "from sklearn import metrics, preprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import evaluate_entity\n",
    "from model_entity import EntityCat\n",
    "from data_utils import CatData\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "# import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0f7c725",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2**15\n",
    "EPOCHS  = 10\n",
    "TOP_K = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c9d49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbff8d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e094616",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1  = ng_sample.read_feather(\"../Data/jobs/leave_one_train\")\n",
    "df_train2 = pd.read_feather(\"../Data/jobs/pos_neg_train_uncode0\")\n",
    "df_test = pd.read_csv(\"../Data/jobs/apps_neg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9255ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1['rating'] = 1\n",
    "df_train_all = pd.concat([df_train1, df_train2], axis=0)\n",
    "df_train_all['flag'] = 1\n",
    "df_test['flag'] = -1\n",
    "df_all = pd.concat([df_train_all, df_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13944671",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input_path = '/home/hao/Documents/MA_thesis_win/hao_jrs/data/clean/sub'\n",
    "apps = pd.read_feather(data_input_path + '/users_sub')\n",
    "apps.rename(columns = {'UserID':'user'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ce63b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'UserID', 'Applies', 'Split', 'City', 'DegreeType', 'State', 'Major', 'CurrentlyEmployed',\n",
    "#          'ManagedOthers', 'WorkHistoryCount', 'TotalYearsExperience',\n",
    "#          'ManagedHowMany', 'JobID', 'WindowID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e4a3016",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all = pd.merge(df_all, apps, how='left', on=['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a1fc2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user', 'item', 'rating', 'flag', 'WindowID', 'Split', 'City', 'State',\n",
       "       'Country', 'ZipCode', 'DegreeType', 'Major', 'GraduationDate',\n",
       "       'WorkHistoryCount', 'TotalYearsExperience', 'CurrentlyEmployed',\n",
       "       'ManagedOthers', 'ManagedHowMany'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7005bc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "049defc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user', 'item', 'rating', 'flag', 'WindowID', 'Split', 'City', 'State',\n",
       "       'Country', 'ZipCode', 'DegreeType', 'Major', 'GraduationDate',\n",
       "       'WorkHistoryCount', 'TotalYearsExperience', 'CurrentlyEmployed',\n",
       "       'ManagedOthers', 'ManagedHowMany'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df_all.columns\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f54a8ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_feature = ['ManagedOthers', 'ManagedHowMany']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf5cc5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['user', 'item'] + context_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fae91863",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in features:\n",
    "    df_all[f] = le.fit_transform(df_all[f].astype('category').cat.codes \\\n",
    "                                                          .fillna(-1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78915b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_all[df_all.flag==1]\n",
    "df_test = df_all[df_all.flag==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4e189490",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.drop(['flag'], axis=1)\n",
    "df_test=df_test.drop(['flag'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "024fde97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train[features+['rating']]\n",
    "df_test=df_test[features+['rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "663c59e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feature=[]\n",
    "cat_feature = features\n",
    "label_name = 'rating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d98e3845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np_train = df_train.values\n",
    "# np_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5a911b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_test = df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "10ad3d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2747605, 5)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "269226d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CatData(np_train)\n",
    "test_dataset = CatData(np_test) \n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=100+1, shuffle=False, num_workers=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c357eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = []\n",
    "for c in cat_feature:\n",
    "    num_unique_values = int(df_all[c].nunique())\n",
    "    embed_dim = int(min(np.ceil(num_unique_values/2), 50))\n",
    "    embedding_size.append([num_unique_values, embed_dim])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ba5209f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[90169, 50], [131997, 50], [2, 1], [253, 50]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8694e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EntityCat(embedding_size = embedding_size, num_numerical_cols = len(num_feature),\n",
    "               output_size = 2)\n",
    "model.to(device)\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2f38e4bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EntityCat(\n",
      "  (all_embeddings): ModuleList(\n",
      "    (0): Embedding(90169, 50)\n",
      "    (1): Embedding(131997, 50)\n",
      "    (2): Embedding(2, 1)\n",
      "    (3): Embedding(253, 50)\n",
      "  )\n",
      "  (embedding_dropout): Dropout(p=0.4, inplace=False)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=151, out_features=100, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.4, inplace=False)\n",
      "    (3): Linear(in_features=100, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4dc1dfa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ManagedOthers-ManagedHowMany'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb_cf = \"-\".join(context_feature) \n",
    "tb_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f71833ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0/10: ---------\n",
      "The time elapse of epoch 000 is: 00: 02: 27\n",
      "train_loss:0.7218547818206605\n",
      "train_HR:0.0            \n",
      "train_NDCG:0.0\n",
      "train_ROC:0.0            \n",
      "test_loss:0.7074419527267505\n",
      "test_HR:0.09912371619711674            \n",
      "test_NDCG:0.04770466257251391\n",
      "test_ROC:0.49968825295123226\n",
      "EPOCH 1/10: ---------\n",
      "The time elapse of epoch 001 is: 00: 02: 26\n",
      "train_loss:0.6938206340585437\n",
      "train_HR:0.0            \n",
      "train_NDCG:0.0\n",
      "train_ROC:0.0            \n",
      "test_loss:0.7031366280252913\n",
      "test_HR:0.11107671184934918            \n",
      "test_NDCG:0.052872137754261014\n",
      "test_ROC:0.5089856106392431\n",
      "EPOCH 2/10: ---------\n",
      "The time elapse of epoch 002 is: 00: 02: 28\n",
      "train_loss:0.6912366918155125\n",
      "train_HR:0.0            \n",
      "train_NDCG:0.0\n",
      "train_ROC:0.0            \n",
      "test_loss:0.7258544233982954\n",
      "test_HR:0.12673136719118064            \n",
      "test_NDCG:0.06139332349654843\n",
      "test_ROC:0.5220352398002449\n",
      "EPOCH 3/10: ---------\n",
      "The time elapse of epoch 003 is: 00: 02: 24\n",
      "train_loss:0.6715300381183624\n",
      "train_HR:0.0            \n",
      "train_NDCG:0.0\n",
      "train_ROC:0.0            \n",
      "test_loss:0.9961180282986022\n",
      "test_HR:0.15808105961691188            \n",
      "test_NDCG:0.07987850454591933\n",
      "test_ROC:0.5527060478389038\n",
      "EPOCH 4/10: ---------\n",
      "The time elapse of epoch 004 is: 00: 02: 36\n",
      "train_loss:0.6461813790457589\n",
      "train_HR:0.0            \n",
      "train_NDCG:0.0\n",
      "train_ROC:0.0            \n",
      "test_loss:1.1240958597854191\n",
      "test_HR:0.17563365683595591            \n",
      "test_NDCG:0.08815669033915212\n",
      "test_ROC:0.5734538503991062\n",
      "EPOCH 5/10: ---------\n",
      "The time elapse of epoch 005 is: 00: 02: 46\n",
      "train_loss:0.6353965508086341\n",
      "train_HR:0.0            \n",
      "train_NDCG:0.0\n",
      "train_ROC:0.0            \n",
      "test_loss:1.1952203750053547\n",
      "test_HR:0.18296967331170666            \n",
      "test_NDCG:0.08994642967592927\n",
      "test_ROC:0.5851298946036533\n",
      "EPOCH 6/10: ---------\n",
      "The time elapse of epoch 006 is: 00: 02: 43\n",
      "train_loss:0.6298776822430747\n",
      "train_HR:0.0            \n",
      "train_NDCG:0.0\n",
      "train_ROC:0.0            \n",
      "test_loss:1.2311676657871717\n",
      "test_HR:0.18961920017229544            \n",
      "test_NDCG:0.09036470680704238\n",
      "test_ROC:0.5931033368779528\n",
      "EPOCH 7/10: ---------\n",
      "The time elapse of epoch 007 is: 00: 02: 39\n",
      "train_loss:0.6266053035145714\n",
      "train_HR:0.0            \n",
      "train_NDCG:0.0\n",
      "train_ROC:0.0            \n",
      "test_loss:1.2490529607337537\n",
      "test_HR:0.20808711687822212            \n",
      "test_NDCG:0.0826932303466745\n",
      "test_ROC:0.5976945390424142\n",
      "EPOCH 8/10: ---------\n",
      "The time elapse of epoch 008 is: 00: 02: 39\n",
      "train_loss:0.6244719858680453\n",
      "train_HR:0.0            \n",
      "train_NDCG:0.0\n",
      "train_ROC:0.0            \n",
      "test_loss:1.2601479218921445\n",
      "test_HR:0.24597865151902654            \n",
      "test_NDCG:0.09056730855990706\n",
      "test_ROC:0.5999652717018211\n",
      "EPOCH 9/10: ---------\n",
      "The time elapse of epoch 009 is: 00: 02: 38\n",
      "train_loss:0.6230284216858092\n",
      "train_HR:0.0            \n",
      "train_NDCG:0.0\n",
      "train_ROC:0.0            \n",
      "test_loss:1.2668699342604273\n",
      "test_HR:0.3060532231360461            \n",
      "test_NDCG:0.11010147122063467\n",
      "test_ROC:0.6012042508513818\n"
     ]
    }
   ],
   "source": [
    "tb_cf = \"-\".join(context_feature) \n",
    "timestamp = datetime.now().strftime('%m-%d_%H-%M-%S')\n",
    "writer = SummaryWriter('runs/trainer_{}_{}'.format(tb_cf, timestamp))\n",
    "plot_n_batch = 10\n",
    "\n",
    "\n",
    "\n",
    "def run_one_epoch(model, epoch_index, writer, data_loader=train_loader, is_train=True):\n",
    "    running_loss = 0.\n",
    "    avg_loss = 0.\n",
    "    HR, NDCG, ROC = [], [], []\n",
    "    \n",
    "    for batch, (cat_data, label) in enumerate(data_loader):\n",
    "        cat_data = cat_data.to(device)\n",
    "        label = label.to(device).float()\n",
    "        \n",
    "        prediction = model(cat_data)[:,1]\n",
    "        loss = loss_function(prediction, label)\n",
    "        running_loss += loss.item()\n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        HR_1batch, NDCG_1batch, ROC_1batch = evaluate_entity.metrics(cat_data, prediction, label, TOP_K, is_train)\n",
    "        HR.append(HR_1batch)\n",
    "        NDCG.append( NDCG_1batch)\n",
    "        ROC.append( ROC_1batch)\n",
    "            \n",
    "    avg_loss = running_loss / (batch +1)  \n",
    " \n",
    "    avg_HR = np.mean(HR)\n",
    "    avg_NDCG = np.mean(NDCG)\n",
    "    avg_ROC = np.mean(ROC)\n",
    "\n",
    "\n",
    "\n",
    "    return avg_loss, avg_HR, avg_NDCG , avg_ROC\n",
    "\n",
    " \n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}/{}: ---------'.format(epoch, EPOCHS))\n",
    "    start_time = time.time()\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    " \n",
    "    model.train(True)\n",
    "    avg_loss_train, avg_HR_train, avg_NDCG_train , avg_ROC_train = run_one_epoch(model,epoch,\\\n",
    "                                                         writer, data_loader=train_loader, is_train=True)\n",
    "    model.train(False)\n",
    "    avg_loss_test, avg_HR_test, avg_NDCG_test, avg_ROC_test = run_one_epoch(model,epoch,\\\n",
    "                                                         writer, data_loader=test_loader, is_train=False)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"The time elapse of epoch {:03d}\".format(epoch) + \" is: \" +\n",
    "          time.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time)))\n",
    "    \n",
    "    print(f\"train_loss:{avg_loss_train}\\ntrain_HR:{avg_HR_train}\\\n",
    "            \\ntrain_NDCG:{avg_NDCG_train}\\ntrain_ROC:{avg_ROC_train}\\\n",
    "            \\ntest_loss:{avg_loss_test}\\ntest_HR:{avg_HR_test}\\\n",
    "            \\ntest_NDCG:{avg_NDCG_test}\\ntest_ROC:{avg_ROC_test}\" )\n",
    " \n",
    "    writer.add_scalars('Loss',\n",
    "                    { 'Train' : avg_loss_train, 'Test' : avg_loss_test },\n",
    "                    epoch )\n",
    " \n",
    "    writer.add_scalars('HitRate',\n",
    "                { 'Train' : avg_HR_train, 'Test' : avg_HR_test },\n",
    "                epoch)\n",
    "    \n",
    "    writer.add_scalars('NDCG',\n",
    "            { 'Train' : avg_NDCG_train, 'Test' : avg_NDCG_test },\n",
    "            epoch)\n",
    "    \n",
    "    writer.add_scalars('ROC',\n",
    "            { 'Train' : avg_ROC_train, 'Test' : avg_ROC_test },\n",
    "            epoch)\n",
    "\n",
    "# # model_path = 'runs/model_{}'.format(timestamp)\n",
    "# # torch.save(model.state_dict(), model_path)\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94563b99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for epoch in tqdm.tqdm(range(EPOCHS)):\n",
    "#     model.train()\n",
    "#     for batch, (cat_data, label) in enumerate(train_loader):\n",
    "#         cat_data = cat_data.to(device)\n",
    "#         label = label.to(device)\n",
    "#         model.zero_grad()\n",
    "#         prediction = model(cat_data)[:,1]\n",
    "#         label = label.float()\n",
    "#         loss = loss_function(prediction, label)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     model.eval()\n",
    "#     HR, NDCG, ROC = evaluate_entity.metrics(model, test_loader, TOP_K)\n",
    "#     print(\"HR: {:.3f}\\tNDCG: {:.3f}\\tROC: {:.3f}\".format(HR, NDCG, ROC))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89c6f71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a51c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
