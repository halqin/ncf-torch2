{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d3cbac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hao/.pyenv/versions/3.6.15/envs/torch-cpu5/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10793a180>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../src')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "from hydra import initialize, compose\n",
    "import pathlib\n",
    "# import config\n",
    "\n",
    "import data_process.neg_sample as ng_sample\n",
    "from data_process.utils import mix_merge\n",
    "from data_process.data_split import data_split_user\n",
    "from evaluate_entity import CustomHR, CustomNDCG, CustomRoc, CustomRoctop, CustomRecall_top, CustomPrecision_top\n",
    "from model_entity import EntityCat\n",
    "from data_utils import CatData\n",
    "from utils.constants import DEFAULT_USER_COL,DEFAULT_ITEM_COL,DEFAULT_RATING_COL, DEFAULT_TIMESTAMP_COL\n",
    "\n",
    "\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, recall_score, precision_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# import argparse\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "452234bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Engine, Events, create_supervised_trainer, create_supervised_evaluator, RemovableEventHandle\n",
    "from ignite.metrics import Accuracy, Loss, Metric\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "from ignite.exceptions import NotComputableError\n",
    "from ignite.metrics.metric import sync_all_reduce, reinit__is_reduced\n",
    "from ignite.contrib.handlers.tqdm_logger import ProgressBar\n",
    "# from ignite.contrib.handlers import TensorboardLogger \n",
    "from ignite.contrib.handlers.wandb_logger import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c9d49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c783c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path=\"../conf\"):\n",
    "    cfg = compose(config_name=\"config\", overrides=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3fca5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type =='cpu':\n",
    "    BATCH_SIZE = cfg.params.batch_size_cpu\n",
    "    EPOCHS  = cfg.params.epochs_cpu\n",
    "else:\n",
    "    BATCH_SIZE = cfg.params.batch_size_gpu\n",
    "    EPOCHS  = cfg.params.epochs_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e094616",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type == 'cpu':\n",
    "    use_amp=False\n",
    "    df_train_pos  = ng_sample.read_feather(pathlib.Path(cfg.path.root, cfg.file.train_pos))\n",
    "    df_train_neg = pd.read_feather(pathlib.Path(cfg.path.root, cfg.file.train_neg))\n",
    "    df_test_ori = pd.read_feather(pathlib.Path(cfg.path.root, cfg.file.test)).iloc[:202,]\n",
    "    df_all_features = pd.read_csv(pathlib.Path(cfg.path.root, cfg.file.all_features))\n",
    "    df_train_pos = df_train_pos.sort_values(by=[DEFAULT_USER_COL]).iloc[:100,].reset_index(drop=True)\n",
    "    df_train_neg = df_train_neg.sort_values(by=[DEFAULT_USER_COL]).iloc[:100*cfg.params.neg_train,].reset_index(drop=True)\n",
    "else:\n",
    "    use_amp=True\n",
    "    df_train_pos  = ng_sample.read_feather(pathlib.Path(cfg.path.root, cfg.file.train_pos))\n",
    "    df_train_neg = pd.read_feather(pathlib.Path(cfg.path.root, cfg.file.train_neg))\n",
    "    df_test_ori = pd.read_feather(pathlib.Path(cfg.path.root, cfg.file.test))\n",
    "    df_all_features = pd.read_csv(pathlib.Path(cfg.path.root, cfg.file.all_features))\n",
    "    df_train_pos = df_train_pos.sort_values(by=[DEFAULT_USER_COL]).reset_index(drop=True)\n",
    "    df_train_neg = df_train_neg.sort_values(by=[DEFAULT_USER_COL]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97918f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pos[DEFAULT_RATING_COL] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9b8c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_index(df1, df2):\n",
    "    df2.index = df2.index//cfg.params.neg_train\n",
    "    return pd.concat([df1, df2], axis=0).sort_index(kind='mregesort').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "103e06ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all = concat_index(df_train_pos, df_train_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9255ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all['flag'] = 1\n",
    "df_test_ori['flag'] = 0\n",
    "df_all = pd.concat([df_train_all, df_test_ori], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bc6348",
   "metadata": {},
   "source": [
    "user features: \n",
    "       'WindowID_user', 'Split', 'City',\n",
    "       'State', 'Country', 'Zip_user', 'DegreeType', 'Major', 'GraduationDate',\n",
    "       'WorkHistoryCount', 'TotalYearsExperience', 'CurrentlyEmployed',\n",
    "       'ManagedOthers', 'ManagedHowMany',\n",
    "       \n",
    "job features: \n",
    "       'WindowID_job', 'City_job',\n",
    "       'State_job', 'Country_job', 'Zip_job', 'StartDate', 'EndDate',"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0715af10",
   "metadata": {},
   "source": [
    "### Choose the features and process data for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "939ed0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userid', 'itemid', 'rating', 'flag'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23a67e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = ['City']\n",
    "user_features_extend = [DEFAULT_USER_COL] + user_features\n",
    "\n",
    "item_features = ['City_job']\n",
    "item_features_extend =[DEFAULT_ITEM_COL] + item_features\n",
    "\n",
    "base_features = [DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0be3c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mix_merge = mix_merge(df_all , df_all_features, user_features_extend, item_features_extend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8084733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cat_encode(df_data, list_f, encoder):\n",
    "    for f in list_f:\n",
    "        df_data[f] = encoder.fit_transform(df_data[f].astype('category').cat.codes.values)\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f75839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _embedding_dimension(df_all_encode, features_to_train, max_dim=50):\n",
    "\n",
    "    embedding_size = []\n",
    "    features_to_em = [i for i in features_to_train if i !=DEFAULT_RATING_COL]\n",
    "    for c in features_to_em:\n",
    "        num_unique_values = int(df_all_encode[c].nunique())\n",
    "        embed_dim = int(min(np.ceil(num_unique_values/2), max_dim))\n",
    "        embedding_size.append([num_unique_values, embed_dim])  \n",
    "    return embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a26ae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(df_mix_merge, features_to_code, features_to_train, max_dim=50):\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    df_all_encode = _cat_encode(df_mix_merge, features_to_code, encoder)\n",
    "    df_train = df_all_encode[df_all.flag==1]\n",
    "    df_test = df_all_encode[df_all.flag==0]\n",
    "    df_train = df_train[features_to_train]\n",
    "    df_test = df_test[features_to_train]\n",
    "    embedding_size = _embedding_dimension(df_all_encode, features_to_train, max_dim)\n",
    "    return df_train, df_test, embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6eb03d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feature=[]\n",
    "features_to_code = df_mix_merge.columns\n",
    "features_to_train = [DEFAULT_USER_COL, DEFAULT_ITEM_COL]+ user_features + item_features +[DEFAULT_RATING_COL]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9370037a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of embedding layers:[[36, 18], [413, 50], [35, 18], [230, 50]]\n"
     ]
    }
   ],
   "source": [
    "df_train,  df_test, embedding_size = encode_data(df_mix_merge, features_to_code, features_to_train, max_dim=cfg.params.emb_dim)\n",
    "\n",
    "print(f'The size of embedding layers:{embedding_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf5983b",
   "metadata": {},
   "source": [
    "## Run data check before training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425e688c",
   "metadata": {},
   "source": [
    "Check the ratio of positive and negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd675e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df_train[df_train.rating==0])/len(df_train[df_train.rating==1]) == cfg.params.neg_train, 'wrong neg/pos ratio in training set'\n",
    "assert len(df_test[df_test.rating==0])/len(df_test[df_test.rating==1]) == cfg.params.neg_test, 'wrong neg/pos ratio in test set '\n",
    "#Check if all the users in test can be found in training set\n",
    "assert sum(np.isin(df_test.userid.unique(), df_train.userid.unique(), assume_unique=True)) == len(df_test.userid.unique()), 'cold start'\n",
    "#The the uniqueness of items between training and test. For a user, on common items between training and test dataset. \n",
    "assert df_all.shape[0] ==df_train.shape[0]+df_test.shape[0], 'wrong data concat'\n",
    "assert sum(df_all.groupby(['userid']).apply(lambda x: len(x['itemid'].unique()))) == df_all.shape[0], 'train and test have overlap item'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fc26c8",
   "metadata": {},
   "source": [
    "## Creat the numpy array for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98032331",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_split, df_val_split = data_split_user(df_train, val_size=0.2)\n",
    "\n",
    "np_train = df_train_split.values\n",
    "np_val = df_val_split.values\n",
    "np_test = df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fb2a567",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1232b2f90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb16f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CatData(np_train)\n",
    "val_dataset = CatData(np_val)\n",
    "test_dataset = CatData(np_test) \n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0,  worker_init_fn=seed_worker,generator=g)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False, num_workers=0,  worker_init_fn=seed_worker,generator=g)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=cfg.params.neg_test+1, shuffle=False, num_workers=0,worker_init_fn=seed_worker,generator=g )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8694e807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EntityCat(\n",
       "  (all_embeddings): ModuleList(\n",
       "    (0): Embedding(36, 18)\n",
       "    (1): Embedding(413, 50)\n",
       "    (2): Embedding(35, 18)\n",
       "    (3): Embedding(230, 50)\n",
       "  )\n",
       "  (mlp_layers): Sequential(\n",
       "    (0): Linear(in_features=136, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "  )\n",
       "  (predict_layer): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EntityCat(embedding_size = embedding_size, num_numerical_cols = len(num_feature),\n",
    "               output_size = 1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7098e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg.params.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686edeec",
   "metadata": {},
   "source": [
    "## Model the training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9670b731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_trans_loss(output):\n",
    "    return output['y_pred'], output['label']\n",
    "\n",
    "val_metrics_train = {\n",
    "    'auc': CustomRoc(),\n",
    "    \"loss\": Loss(criterion, output_transform=output_trans_loss)\n",
    "}\n",
    "\n",
    "val_metrics_test = {\n",
    "    'hr': CustomHR(),\n",
    "    'ndcg': CustomNDCG(),\n",
    "    'auc': CustomRoc(),\n",
    "    'roc_top': CustomRoctop(),\n",
    "    'recall_top': CustomRecall_top(threshold=0.5),\n",
    "    'precision_top': CustomPrecision_top(threshold=0.5),\n",
    "    \"loss\": Loss(criterion, output_transform=output_trans_loss)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "df93a20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ignite.engine.events.RemovableEventHandle at 0x130716f98>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "def train_step(engine, batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch[0].to(device), batch[1].to(device)\n",
    "    with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "        y_pred = model(x).reshape(1,-1).flatten()\n",
    "        loss = criterion(y_pred, y.float())\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    return loss.item()\n",
    "\n",
    "def validation_step(engine, batch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, label = batch[0].to(device), batch[1].to(device)\n",
    "        y_pred = model(x).reshape(1,-1).flatten()\n",
    "        label=label.float()\n",
    "        return {'label':label, 'y_pred':y_pred}\n",
    "\n",
    "def test_step(engine, batch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, label = batch[0].to(device), batch[1].to(device)\n",
    "        y_pred = model(x).reshape(1,-1).flatten()\n",
    "        label=label.float()\n",
    "        y_pred_top, indices = torch.topk(y_pred, engine.state.topk)\n",
    "        y_pred_top = y_pred_top.detach().cpu().numpy()\n",
    "        reco_item = torch.take(x[:,1], indices).cpu().numpy().tolist()\n",
    "        pos_item = x[0,1].cpu().numpy().tolist()  # ground truth, item id\n",
    "        label_top = label[indices].cpu().numpy()\n",
    "        return {'pos_item':pos_item, 'reco_item':reco_item, 'y_pred_top':y_pred_top, 'label_top':label_top, 'label':label, 'y_pred':y_pred}\n",
    "\n",
    "trainer = Engine(train_step)\n",
    "\n",
    "train_evaluator = Engine(validation_step)\n",
    "# train_evaluator.state_dict_user_keys.append('topk')\n",
    "\n",
    "val_evaluator = Engine(validation_step)\n",
    "# val_evaluator.state_dict_user_keys.append('topk')\n",
    "\n",
    "test_evaluator = Engine(test_step)\n",
    "test_evaluator.state_dict_user_keys.append('topk')\n",
    "\n",
    "# @val_evaluator.on(Events.STARTED)\n",
    "# def init_user_value():\n",
    "#     val_evaluator.state.topk=3\n",
    "    \n",
    "# @train_evaluator.on(Events.STARTED)\n",
    "# def init_user_value():\n",
    "#     train_evaluator.state.topk=3\n",
    "\n",
    "@train_evaluator.on(Events.STARTED)\n",
    "def init_user_value():\n",
    "    test_evaluator.state.topk=cfg.params.topk\n",
    "    \n",
    "    \n",
    "# Attach metrics to the evaluators\n",
    "for name, metric in val_metrics_train.items():\n",
    "    metric.attach(train_evaluator, name)\n",
    "\n",
    "for name, metric in val_metrics_train.items():\n",
    "    metric.attach(val_evaluator, name)\n",
    "\n",
    "    \n",
    "for name, metric in val_metrics_test.items():\n",
    "    metric.attach(test_evaluator, name)\n",
    "    \n",
    "# Eearly_stop \n",
    "def score_function(engine):\n",
    "    val_loss = engine.state.metrics['auc']\n",
    "    return val_loss\n",
    "\n",
    "Eearly_stop_handler = EarlyStopping(patience=cfg.params.patience, score_function=score_function, trainer=trainer)\n",
    "val_evaluator.add_event_handler(Events.COMPLETED, Eearly_stop_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8b9d6ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    train_evaluator.run(train_loader)\n",
    "    metrics = train_evaluator.state.metrics\n",
    "    auc = metrics['auc']\n",
    "    loss = metrics['loss']\n",
    "    print(f'Training Results- Epoch[{trainer.state.epoch}]  Avg loss: {loss:.2f} \\\n",
    "          Avg auc:{auc:.2f}')\n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    val_evaluator.run(val_loader)\n",
    "    metrics = val_evaluator.state.metrics\n",
    "    auc = metrics['auc']\n",
    "    loss = metrics['loss']\n",
    "    print(f'Validation Results- Epoch[{trainer.state.epoch}]  Avg loss: {loss:.2f} \\\n",
    "          Avg auc:{auc:.2f}')\n",
    "\n",
    "    \n",
    "@trainer.on(Events.COMPLETED)\n",
    "def log_test_results(trainer):\n",
    "    test_evaluator.run(test_loader)\n",
    "    metrics = test_evaluator.state.metrics\n",
    "    hr = metrics['hr']\n",
    "    ndcg = metrics['ndcg']\n",
    "    auc = metrics['auc']\n",
    "    roc_top = metrics['roc_top']\n",
    "    recall = metrics['recall_top']\n",
    "    precision = metrics['precision_top']\n",
    "    loss = metrics['loss']\n",
    "    print(f\"Test Results - Epoch[{trainer.state.epoch}]  Avg loss: {loss:.2f} \\\n",
    "     Avg ndcg: {ndcg:.2f}  Avg auc: {auc:.2f}  Avg auc_top: {roc_top:.2f} \\\n",
    "      Avg recall: {recall:.2f}  Avg precision: {precision:.2f}\")\n",
    "\n",
    "pbar = ProgressBar(persist=False)\n",
    "pbar.attach(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "af997b32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer.run(train_loader, max_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b18f030d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtiyuok2023\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.20 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.19"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/hao/Documents/MA_thesis/ncf-torch2/src/jupyter/wandb/run-20220704_134526-1hwiim4f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/tiyuok2023/pytorch-jrs/runs/1hwiim4f\" target=\"_blank\">City-City_job</a></strong> to <a href=\"https://wandb.ai/tiyuok2023/pytorch-jrs\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">City-City_job</strong>: <a href=\"https://wandb.ai/tiyuok2023/pytorch-jrs/runs/1hwiim4f\" target=\"_blank\">https://wandb.ai/tiyuok2023/pytorch-jrs/runs/1hwiim4f</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220704_134526-1hwiim4f/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config_dict = dict(cfg.params)\n",
    "config_dict['Features']='-'.join(user_features+item_features)\n",
    "# wandb_logger = WandBLogger(\n",
    "#     project=\"pytorch-jrs\",\n",
    "#     name=\"-\".join(user_features)+'-'+'-'.join(item_features),\n",
    "#     config=config_dict,\n",
    "#     tags=[\"entity\", \"jrs\"]\n",
    "# )\n",
    "\n",
    "to_save = {'model': model}\n",
    "checkpoint_handler = ModelCheckpoint(\n",
    "    wandb_logger.run.dir,\n",
    "    n_saved=1, filename_prefix='best',\n",
    "    score_name=\"auc\",\n",
    "    global_step_transform=global_step_from_engine(trainer)\n",
    ")\n",
    "\n",
    "val_evaluator.add_event_handler(Events.COMPLETED, checkpoint_handler, to_save)\n",
    "\n",
    "    \n",
    "wandb_logger.attach_output_handler(\n",
    "    trainer,\n",
    "    event_name=Events.ITERATION_COMPLETED,\n",
    "    tag=\"training\",\n",
    "    output_transform=lambda loss: {\"loss\": loss}\n",
    ")\n",
    "\n",
    "wandb_logger.attach_output_handler(\n",
    "    train_evaluator,\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    "    tag=\"training\",\n",
    "    metric_names=['loss','auc'],\n",
    "    global_step_transform=lambda *_: trainer.state.iteration,\n",
    ")\n",
    "\n",
    "wandb_logger.attach_output_handler(\n",
    "    val_evaluator,\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    "    tag=\"validation\",\n",
    "    metric_names=['loss',\"auc\"],\n",
    "    global_step_transform=lambda *_: trainer.state.iteration,\n",
    ")\n",
    "\n",
    "\n",
    "wandb_logger.attach_output_handler(\n",
    "    test_evaluator,\n",
    "    event_name=Events.COMPLETED,\n",
    "    tag=\"test\",\n",
    "    metric_names=['loss',\"auc\", 'hr', 'ndcg', 'roc_top', 'recall_top', 'precision_top'],\n",
    "    global_step_transform=lambda *_: trainer.state.iteration,\n",
    ")\n",
    "\n",
    "\n",
    "wandb_logger.attach_opt_params_handler(\n",
    "    trainer,\n",
    "    event_name=Events.ITERATION_STARTED,\n",
    "    optimizer=optimizer,\n",
    "    param_name='lr'  # optional\n",
    ")\n",
    "\n",
    "# wandb_logger.watch(model) \n",
    "\n",
    "# trainer.run(train_loader, max_epochs=EPOCHS)\n",
    "wandb_logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea211e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fec2820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21ae829a",
   "metadata": {},
   "source": [
    "## Quantity evaluation \n",
    "display the recommended items for the user. Sample the recommended test users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c983bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users_test = df_test[DEFAULT_USER_COL].unique()\n",
    "np.random.seed(123)\n",
    "sub_users_test = np.random.choice(unique_users_test, 2, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "db76ba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_sub = df_test[df_test[DEFAULT_USER_COL].isin(sub_users_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "931da7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index =df_test[DEFAULT_USER_COL].isin(sub_users_test).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ca7f29e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_sub_ori = df_all[df_all.index.isin(sample_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4ada6377",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_test_sub = df_test_sub.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "39ba3b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_sample = CatData(np_test_sub)\n",
    "test_sample_loader = data.DataLoader(test_dataset_sample, batch_size=cfg.params.neg_test+1, shuffle=False, num_workers=0,worker_init_fn=seed_worker,generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "23d79584",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecoList(Metric):\n",
    "    '''\n",
    "    The recommendation list \n",
    "    '''\n",
    "    def __init__(self, output_transform=lambda x: [x['pos_item'], x['reco_item'], x['userid'], x['y_pred_top'], x['indices']], device=\"cpu\"):\n",
    "#         self._reco_dict = []\n",
    "        self.item= np.array([])\n",
    "        self.userid= np.array([])\n",
    "        self.prob= np.array([])\n",
    "        self.indices = []\n",
    "#         self.cnt = 0\n",
    "        super(RecoList, self).__init__(output_transform=output_transform, device=device)\n",
    "\n",
    "    @reinit__is_reduced\n",
    "    def reset(self):\n",
    "        self.item= np.array([])\n",
    "        self.userid= np.array([])\n",
    "        self.prob= np.array([])\n",
    "#         self.cnt = 0\n",
    "        super(RecoList, self).reset()\n",
    "\n",
    "    @reinit__is_reduced\n",
    "    def update(self, output):\n",
    "        gt_item = output[0]\n",
    "        reco_item = output[1]\n",
    "        userid = output[2]\n",
    "        prob = output[3]\n",
    "        indices = output[4]\n",
    "        self.item = np.append(self.item, reco_item)\n",
    "        self.userid = np.append(self.userid, userid)\n",
    "        self.prob = np.append(self.prob, prob)\n",
    "        self.indices.append(indices)\n",
    "        \n",
    "    @sync_all_reduce(\"_reco_dict\")\n",
    "    def compute(self):\n",
    "        return self.indices, self.prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0a9c8adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metrics_test_quanlity = {\n",
    "    'recolist': RecoList()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "16302697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_q_step(engine, batch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, label = batch[0].to(device), batch[1].to(device)\n",
    "        y_pred = model(x).reshape(1,-1).flatten()\n",
    "#         print(y_pred)\n",
    "        label=label.float()\n",
    "        y_pred_top, indices = torch.topk(y_pred, engine.state.topk)\n",
    "        y_pred_top = y_pred_top.cpu().numpy().tolist()\n",
    "        y_pred_top = y_pred_top\n",
    "        reco_item = torch.take(x[:,1], indices).cpu().numpy().tolist()\n",
    "        pos_item = x[0,1].cpu().numpy().tolist()  # ground truth, item id \n",
    "        userid = x[:engine.state.topk,0].cpu().numpy().tolist()\n",
    "        return {'reco_item': reco_item, 'pos_item':pos_item, 'userid':userid, 'y_pred_top':y_pred_top, 'indices':indices.cpu().numpy().tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a4526dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_q_evaluator=Engine(test_q_step)\n",
    "for name, metric in val_metrics_test_quanlity.items():\n",
    "    metric.attach(test_q_evaluator, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "906315e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_q_evaluator.state_dict_user_keys.append('topk')\n",
    "\n",
    "@test_q_evaluator.on(Events.STARTED)\n",
    "def init_user_value():\n",
    "    test_q_evaluator.state.topk=cfg.params.topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "362f36eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State:\n",
       "\titeration: 2\n",
       "\tepoch: 1\n",
       "\tepoch_length: 2\n",
       "\tmax_epochs: 1\n",
       "\toutput: <class 'dict'>\n",
       "\tbatch: <class 'list'>\n",
       "\tmetrics: <class 'dict'>\n",
       "\tdataloader: torch.utils.data.dataloader.DataLoader\n",
       "\tseed: <class 'NoneType'>\n",
       "\ttimes: <class 'dict'>\n",
       "\ttopk: 10"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_q_evaluator.run(test_sample_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b0fa6bc4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bb, prob =test_q_evaluator.state.metrics['recolist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "66e91fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9f4b3e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_sub_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5e1a9e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train = len(df_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e931f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_indices = []\n",
    "for i in range(len(bb)):\n",
    "    reco_indices += [cfg.params.neg_test*(i)+j for j in bb[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dc208234",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reco = df_test_sub_ori.iloc[reco_indices].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "427e696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reco['prob'] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e50cbd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>itemid</th>\n",
       "      <th>rating</th>\n",
       "      <th>flag</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>7</td>\n",
       "      <td>732328</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.432161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>7</td>\n",
       "      <td>382423</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>7</td>\n",
       "      <td>725768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.413199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>7</td>\n",
       "      <td>703889</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.412339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>7</td>\n",
       "      <td>663485</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.398364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userid  itemid  rating  flag      prob\n",
       "578       7  732328       0     0  0.432161\n",
       "534       7  382423       0     0  0.416606\n",
       "533       7  725768       0     0  0.413199\n",
       "500       7  703889       1     0  0.412339\n",
       "582       7  663485       0     0  0.398364"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "37b3b0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_info = pd.read_csv('../../data/jobs/jobid_title.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e3401e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_info.rename(columns={'item_id':'itemid'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "eac05894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>itemid</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Security Engineer/Technical Lead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>SAP Business Analyst / WM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>P/T HUMAN RESOURCES ASSISTANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>Route Delivery Drivers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>Housekeeping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091918</th>\n",
       "      <td>1091918</td>\n",
       "      <td>1116242</td>\n",
       "      <td>ELECTRICAL SPECIALIST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091919</th>\n",
       "      <td>1091919</td>\n",
       "      <td>1116253</td>\n",
       "      <td>General and Assistant Managers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091920</th>\n",
       "      <td>1091920</td>\n",
       "      <td>1116294</td>\n",
       "      <td>Assistant Retail Store Manager - Retail Sales ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091921</th>\n",
       "      <td>1091921</td>\n",
       "      <td>1116304</td>\n",
       "      <td>Career Experience Specialist - Career Services...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091922</th>\n",
       "      <td>1091922</td>\n",
       "      <td>1116307</td>\n",
       "      <td>ACCOUNT EXECUTIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1091923 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0   itemid  \\\n",
       "0                 0        1   \n",
       "1                 1        4   \n",
       "2                 2        7   \n",
       "3                 3        8   \n",
       "4                 4        9   \n",
       "...             ...      ...   \n",
       "1091918     1091918  1116242   \n",
       "1091919     1091919  1116253   \n",
       "1091920     1091920  1116294   \n",
       "1091921     1091921  1116304   \n",
       "1091922     1091922  1116307   \n",
       "\n",
       "                                                     Title  \n",
       "0                         Security Engineer/Technical Lead  \n",
       "1                                SAP Business Analyst / WM  \n",
       "2                            P/T HUMAN RESOURCES ASSISTANT  \n",
       "3                                   Route Delivery Drivers  \n",
       "4                                             Housekeeping  \n",
       "...                                                    ...  \n",
       "1091918                              ELECTRICAL SPECIALIST  \n",
       "1091919                     General and Assistant Managers  \n",
       "1091920  Assistant Retail Store Manager - Retail Sales ...  \n",
       "1091921  Career Experience Specialist - Career Services...  \n",
       "1091922                                  ACCOUNT EXECUTIVE  \n",
       "\n",
       "[1091923 rows x 3 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0a72dfb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "{'itemid'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-da31bf7f8400>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_reco\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'itemid'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.15/envs/torch-cpu5/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     )\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.15/envs/torch-cpu5/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.15/envs/torch-cpu5/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    981\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_rkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.15/envs/torch-cpu5/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: {'itemid'}"
     ]
    }
   ],
   "source": [
    "pd.merge(df_reco, job_info, how='left', on={'itemid'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7037b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa323a99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011d296c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4abe8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
