{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d3cbac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa95aabbb70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../src')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "# import config\n",
    "\n",
    "import data_process.neg_sample as ng_sample\n",
    "# import evaluate_entity\n",
    "from evaluate_entity import CustomHR, CustomNDCG, CustomRoc, CustomRoctop, CustomRecall_top, CustomPrecision_top\n",
    "from model_entity import EntityCat\n",
    "from data_utils import CatData\n",
    "from utils.constants import DEFAULT_USER_COL,DEFAULT_ITEM_COL,DEFAULT_RATING_COL, DEFAULT_TIMESTAMP_COL\n",
    "\n",
    "from sklearn import metrics, preprocessing\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, recall_score, precision_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# import argparse\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "452234bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Engine, Events, create_supervised_trainer, create_supervised_evaluator, RemovableEventHandle\n",
    "from ignite.metrics import Accuracy, Loss, Metric\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "from ignite.exceptions import NotComputableError\n",
    "from ignite.metrics.metric import sync_all_reduce, reinit__is_reduced\n",
    "from ignite.contrib.handlers.tqdm_logger import ProgressBar\n",
    "# from ignite.contrib.handlers import TensorboardLogger \n",
    "from ignite.contrib.handlers.wandb_logger import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c6c9d49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cbff8d78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f3fca5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "9e094616",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == 'cpu':\n",
    "    df_train1  = ng_sample.read_feather(\"../../data/jobs/leave_one_train.csv\")\n",
    "    df_train2 = pd.read_feather(\"../../data/jobs/leave_one_train_neg\")\n",
    "    df_test_ori = pd.read_feather(\"../../data/jobs/test_pos_neg\").iloc[:202,]\n",
    "    df_all_features = pd.read_csv('../../data/jobs/merged_sub_clean.csv')\n",
    "    df_train1 = df_train1.sort_values(by=[DEFAULT_USER_COL]).iloc[:100,].reset_index(drop=True)\n",
    "    df_train2 = df_train2.sort_values(by=[DEFAULT_USER_COL]).iloc[:100*NEG_TRAIN,].reset_index(drop=True)\n",
    "else:\n",
    "    df_train1  = ng_sample.read_feather(\"../../data/jobs/leave_one_train.csv\")\n",
    "    df_train2 = pd.read_feather(\"../../data/jobs/leave_one_train_neg\")\n",
    "    df_test_ori = pd.read_feather(\"../../data/jobs/test_pos_neg\")\n",
    "    df_all_features = pd.read_csv('../../data/jobs/merged_sub_clean.csv')\n",
    "    df_train1 = df_train1.sort_values(by=[DEFAULT_USER_COL]).reset_index(drop=True)\n",
    "    df_train2 = df_train2.sort_values(by=[DEFAULT_USER_COL]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "35239145",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device =='cpu':\n",
    "    BATCH_SIZE = 20\n",
    "else:\n",
    "    BATCH_SIZE = 2**17\n",
    "EPOCHS  = 200\n",
    "TOP_K = 10\n",
    "NEG_TEST = 100\n",
    "NEG_TRAIN = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "97918f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1[DEFAULT_RATING_COL] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "b9b8c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_index(df1, df2, NEG_TRAIN):\n",
    "    df2.index = df2.index//NEG_TRAIN\n",
    "    return pd.concat([df1, df2], axis=0).sort_index(kind='mregesort').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "103e06ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all = concat_index(df_train1, df_train2, NEG_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "9255ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all['flag'] = 1\n",
    "df_test_ori['flag'] = 0\n",
    "df_all = pd.concat([df_train_all, df_test_ori], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bc6348",
   "metadata": {},
   "source": [
    "user features: \n",
    "       'WindowID_user', 'Split', 'City',\n",
    "       'State', 'Country', 'Zip_user', 'DegreeType', 'Major', 'GraduationDate',\n",
    "       'WorkHistoryCount', 'TotalYearsExperience', 'CurrentlyEmployed',\n",
    "       'ManagedOthers', 'ManagedHowMany',\n",
    "       \n",
    "job features: \n",
    "       'WindowID_job', 'City_job',\n",
    "       'State_job', 'Country_job', 'Zip_job', 'StartDate', 'EndDate',"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0715af10",
   "metadata": {},
   "source": [
    "### Choose the features for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "23a67e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = ['City']\n",
    "user_features_extend = [DEFAULT_USER_COL] + user_features\n",
    "\n",
    "item_features = ['City_job']\n",
    "item_features_extend =[DEFAULT_ITEM_COL] + item_features\n",
    "\n",
    "base_features = [DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "22ad8b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_filter(df_data, name_col):\n",
    "    df_uni=df_data[~(df_data[name_col].duplicated())].reset_index(drop=True)\n",
    "    return df_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "b30a460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_merge(list_f, df_all, df_all_f, default_x_col):\n",
    "    df_x_features = df_all_f[list_f]\n",
    "    df_x_unique = unique_filter(df_x_features, default_x_col)\n",
    "    df_merge_x = df_all.merge(df_x_unique, how='left', on=[default_x_col])\n",
    "    return df_merge_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "7acbca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_item_merge(mode, df_all, df_all_features, feature_list):\n",
    "    if mode =='user':\n",
    "        df_merge_x = feature_merge(feature_list, df_all, df_all_features,\\\n",
    "                                      DEFAULT_USER_COL)\n",
    "    if mode == 'item':\n",
    "        df_merge_x = feature_merge(feature_list, df_all, df_all_features, \\\n",
    "                                   DEFAULT_ITEM_COL)\n",
    "\n",
    "    return df_merge_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "e0e7f502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_merge(df_all, df_all_features, f_list_user, f_list_item):\n",
    "    df_merge_user = feature_merge(f_list_user, df_all, df_all_features, \\\n",
    "                                  DEFAULT_USER_COL)\n",
    "    df_merge_item = feature_merge(f_list_item, df_all, df_all_features, \\\n",
    "                                  DEFAULT_ITEM_COL)\n",
    "    df_merge_x = pd.concat([df_merge_user[f_list_user], \\\n",
    "                             df_merge_item[f_list_item]], axis=1)\n",
    "    df_merge_x[DEFAULT_RATING_COL] = df_all[DEFAULT_RATING_COL]\n",
    "    assert df_all.shape[0] == df_merge_x.shape[0], \"wrong merge\"\n",
    "    return df_merge_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d0be3c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mix_merge = mix_merge(df_all, df_all_features, user_features_extend, item_features_extend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "7005bc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "fae91863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_encode(df_data, list_f):\n",
    "    for f in list_f:\n",
    "        df_data[f] = le.fit_transform(df_data[f].astype('category').cat.codes.values)\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "9370037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_code = df_mix_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "5192e4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_encode = cat_encode(df_mix_merge, features_to_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b2b69e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_encode[DEFAULT_RATING_COL] = df_all[DEFAULT_RATING_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "78915b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_all_encode[df_all.flag==1]\n",
    "df_test = df_all_encode[df_all.flag==0]\n",
    "\n",
    "# df_train=df_train.drop(['flag'], axis=1)\n",
    "# df_test=df_test.drop(['flag'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "e8e49d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_train = [DEFAULT_USER_COL, DEFAULT_ITEM_COL]+ user_features + item_features +[DEFAULT_RATING_COL]\n",
    "df_train = df_train[features_to_train]\n",
    "df_test = df_test[features_to_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "5a896e00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CityCity_job'"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb_cf = \"-\".join(user_features)+'-'.join(item_features)\n",
    "tb_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "136f85ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train[features_to_train]\n",
    "df_test=df_test[features_to_train]\n",
    "\n",
    "num_feature=[]\n",
    "features_to_train.remove(DEFAULT_RATING_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "9ab2f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split_user(df_train, val_size=0.2):\n",
    "    unique_user = df_train[DEFAULT_USER_COL].unique()\n",
    "    val_user = np.random.choice(unique_user, int(val_size*len(unique_user)), replace=False)\n",
    "    df_train_split = df_train[~(df_train[DEFAULT_USER_COL].isin(val_user))]\n",
    "    df_val_split = df_train[df_train[DEFAULT_USER_COL].isin(val_user)]\n",
    "    return df_train_split, df_val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "98032331",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_split, df_val_split = data_split_user(df_train, val_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "d98e3845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np_train = df_train_split.values\n",
    "np_val = df_val_split.values\n",
    "np_test = df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "6fb2a567",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa8c0c19a90>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "269226d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CatData(np_train)\n",
    "val_dataset = CatData(np_val)\n",
    "test_dataset = CatData(np_test) \n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0,  worker_init_fn=seed_worker,generator=g)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=NEG_TRAIN+1, shuffle=False, num_workers=0,  worker_init_fn=seed_worker,generator=g)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=NEG_TEST+1, shuffle=False, num_workers=0,worker_init_fn=seed_worker,generator=g )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "c357eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = []\n",
    "for c in features_to_train:\n",
    "    num_unique_values = int(df_all_encode[c].nunique())\n",
    "    embed_dim = int(min(np.ceil(num_unique_values/2), 50))\n",
    "    embedding_size.append([num_unique_values, embed_dim])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "8694e807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EntityCat(\n",
       "  (all_embeddings): ModuleList(\n",
       "    (0): Embedding(89946, 50)\n",
       "    (1): Embedding(139292, 50)\n",
       "    (2): Embedding(6296, 50)\n",
       "    (3): Embedding(5405, 50)\n",
       "  )\n",
       "  (embedding_dropout): Dropout(p=0.4, inplace=False)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EntityCat(embedding_size = embedding_size, num_numerical_cols = len(num_feature),\n",
    "               output_size = 2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "a7098e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "2f38e4bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EntityCat(\n",
      "  (all_embeddings): ModuleList(\n",
      "    (0): Embedding(89946, 50)\n",
      "    (1): Embedding(139292, 50)\n",
      "    (2): Embedding(6296, 50)\n",
      "    (3): Embedding(5405, 50)\n",
      "  )\n",
      "  (embedding_dropout): Dropout(p=0.4, inplace=False)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.4, inplace=False)\n",
      "    (3): Linear(in_features=100, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "9670b731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_trans_loss(output):\n",
    "    return output['y_pred'], output['label']\n",
    "\n",
    "val_metrics = {\n",
    "#     \"customEva\": CustomEva(topk=3, threshold=0.5),\n",
    "    'hr': CustomHR(),\n",
    "    'ndcg': CustomNDCG(),\n",
    "    'roc': CustomRoc(),\n",
    "    'roc_top': CustomRoctop(),\n",
    "    'recall_top': CustomRecall_top(threshold=0.5),\n",
    "    'precision_top': CustomPrecision_top(threshold=0.5),\n",
    "    \"loss\": Loss(criterion, output_transform=output_trans_loss)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "df93a20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ignite.engine.events.RemovableEventHandle at 0x7fa8c156d190>"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_step(engine, batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch[0].to(device), batch[1].to(device)\n",
    "    y_pred = model(x)[:,1]\n",
    "    loss = criterion(y_pred, y.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "trainer = Engine(train_step)\n",
    "\n",
    "def validation_step(engine, batch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, label = batch[0].to(device), batch[1].to(device)\n",
    "        y_pred = model(x)[:,1]\n",
    "        label=label.float()\n",
    "        \n",
    "        y_pred_top, indices = torch.topk(y_pred, engine.state.topk)\n",
    "        y_pred_top = y_pred_top.detach().cpu().numpy()\n",
    "        reco_item = torch.take(x[:,1], indices).cpu().numpy().tolist()\n",
    "        pos_item = x[0,1].cpu().numpy().tolist()  # ground truth, item id\n",
    "        label_top = label[indices].cpu().numpy()\n",
    "        \n",
    "        return {'pos_item':pos_item, 'reco_item':reco_item, 'y_pred_top':y_pred_top, 'label_top':label_top, 'label':label, 'y_pred':y_pred}\n",
    "#         return {'pos_item':pos_item, 'reco_item':reco_item,'label':label,'y_pred':y_pred }\n",
    "\n",
    "train_evaluator = Engine(validation_step)\n",
    "train_evaluator.state_dict_user_keys.append('topk')\n",
    "\n",
    "val_evaluator = Engine(validation_step)\n",
    "val_evaluator.state_dict_user_keys.append('topk')\n",
    "\n",
    "@val_evaluator.on(Events.STARTED)\n",
    "def init_user_value():\n",
    "    val_evaluator.state.topk=3\n",
    "    \n",
    "@train_evaluator.on(Events.STARTED)\n",
    "def init_user_value():\n",
    "    train_evaluator.state.topk=3\n",
    "    \n",
    "    \n",
    "# Attach metrics to the evaluators\n",
    "for name, metric in val_metrics.items():\n",
    "    metric.attach(train_evaluator, name)\n",
    "\n",
    "for name, metric in val_metrics.items():\n",
    "    metric.attach(val_evaluator, name)\n",
    "\n",
    "# Eearly_stop \n",
    "def score_function(engine):\n",
    "    val_loss = engine.state.metrics['roc']\n",
    "    return val_loss\n",
    "\n",
    "Eearly_stop_handler = EarlyStopping(patience=10, score_function=score_function, trainer=trainer)\n",
    "val_evaluator.add_event_handler(Events.COMPLETED, Eearly_stop_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "8b9d6ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    train_evaluator.run(train_loader)\n",
    "    metrics = train_evaluator.state.metrics\n",
    "    hr = metrics['hr']\n",
    "    ndcg = metrics['ndcg']\n",
    "    roc = metrics['roc']\n",
    "    roc_top = metrics['roc_top']\n",
    "    recall = metrics['recall_top']\n",
    "    precision = metrics['precision_top']\n",
    "    loss = metrics['loss']\n",
    "    print(f\"Training Results - Epoch[{trainer.state.epoch}]  Avg loss: {loss:.2f} \\\n",
    "     Avg ndcg: {ndcg:.2f}  Avg roc: {roc:.2f}  Avg roc_top: {roc_top:.2f} \\\n",
    "      Avg recall: {recall:.2f}  Avg precision: {precision:.2f}\")\n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    val_evaluator.run(val_loader)\n",
    "    metrics = val_evaluator.state.metrics\n",
    "    hr = metrics['hr']\n",
    "    ndcg = metrics['ndcg']\n",
    "    roc = metrics['roc']\n",
    "    roc_top = metrics['roc_top']\n",
    "    recall = metrics['recall_top']\n",
    "    precision = metrics['precision_top']\n",
    "    loss = metrics['loss']\n",
    "    print(f\"Validation Results - Epoch[{trainer.state.epoch}]  Avg loss: {loss:.2f} \\\n",
    "     Avg ndcg: {ndcg:.2f}  Avg roc: {roc:.2f}  Avg roc_top: {roc_top:.2f} \\\n",
    "      Avg recall: {recall:.2f}  Avg precision: {precision:.2f}\")\n",
    "\n",
    "pbar = ProgressBar(persist=True)\n",
    "# pbar.attach(trainer)\n",
    "pbar.attach(val_evaluator)\n",
    "# from ignite.handlers import Timer\n",
    "# timer = Timer(average=True)\n",
    "# timer.attach(trainer,\n",
    "#              start=Events.STARTED,\n",
    "#              resume=Events.EPOCH_STARTED,\n",
    "#              pause=Events.EPOCH_COMPLETED,\n",
    "#              step=Events.EPOCH_COMPLETED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "af997b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch[1]  Avg loss: 0.78      Avg ndcg: 0.00  Avg roc: 0.59  Avg roc_top: 0.38       Avg recall: 0.82  Avg precision: 0.41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62c3e0aec6a42e5b88bc7c136c9ac3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/109441]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: \n",
      "Engine run is terminating due to exception: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [274]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:704\u001b[0m, in \u001b[0;36mEngine.run\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch_length should be provided if data is None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m--> 704\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:783\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 783\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:466\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:760\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mTERMINATE)\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 760\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fire_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvents\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEPOCH_COMPLETED\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    761\u001b[0m time_taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m handlers_start_time\n\u001b[1;32m    762\u001b[0m \u001b[38;5;66;03m# update time wrt handlers\u001b[39;00m\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:421\u001b[0m, in \u001b[0;36mEngine._fire_event\u001b[0;34m(self, event_name, *event_args, **event_kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(event_kwargs)\n\u001b[1;32m    420\u001b[0m first, others \u001b[38;5;241m=\u001b[39m ((args[\u001b[38;5;241m0\u001b[39m],), args[\u001b[38;5;241m1\u001b[39m:]) \u001b[38;5;28;01mif\u001b[39;00m (args \u001b[38;5;129;01mand\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m ((), args)\n\u001b[0;32m--> 421\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfirst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevent_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mothers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [273]\u001b[0m, in \u001b[0;36mlog_validation_results\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;129m@trainer\u001b[39m\u001b[38;5;241m.\u001b[39mon(Events\u001b[38;5;241m.\u001b[39mEPOCH_COMPLETED)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_validation_results\u001b[39m(trainer):\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mval_evaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m val_evaluator\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mmetrics\n\u001b[1;32m     21\u001b[0m     hr \u001b[38;5;241m=\u001b[39m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:704\u001b[0m, in \u001b[0;36mEngine.run\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch_length should be provided if data is None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m--> 704\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:783\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 783\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:466\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:753\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_engine()\n\u001b[0;32m--> 753\u001b[0m time_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once_on_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;66;03m# time is available for handlers but must be update after fire\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimes[Events\u001b[38;5;241m.\u001b[39mEPOCH_COMPLETED\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m time_taken\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:841\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_STARTED)\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_function(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbatch)\n\u001b[0;32m--> 841\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fire_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvents\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mITERATION_COMPLETED\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_terminate \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_terminate_single_epoch:\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mTERMINATE_SINGLE_EPOCH, iter_counter\u001b[38;5;241m=\u001b[39miter_counter)\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:421\u001b[0m, in \u001b[0;36mEngine._fire_event\u001b[0;34m(self, event_name, *event_args, **event_kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(event_kwargs)\n\u001b[1;32m    420\u001b[0m first, others \u001b[38;5;241m=\u001b[39m ((args[\u001b[38;5;241m0\u001b[39m],), args[\u001b[38;5;241m1\u001b[39m:]) \u001b[38;5;28;01mif\u001b[39;00m (args \u001b[38;5;129;01mand\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m ((), args)\n\u001b[0;32m--> 421\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfirst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevent_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mothers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/metrics/metric.py:311\u001b[0m, in \u001b[0;36mMetric.iteration_completed\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate((tensor_o1, tensor_o2))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/metrics/metric.py:596\u001b[0m, in \u001b[0;36mreinit__is_reduced.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m: Metric, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m     \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_reduced \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/MA_thesis_u/ncf-torch2/src/jupyter/../../src/evaluate_entity.py:212\u001b[0m, in \u001b[0;36mCustomPrecision_top.update\u001b[0;34m(self, output)\u001b[0m\n\u001b[1;32m    210\u001b[0m y \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    211\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_precision_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mprecision\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_threshold\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/MA_thesis_u/ncf-torch2/src/jupyter/../../src/evaluate_entity.py:37\u001b[0m, in \u001b[0;36mprecision\u001b[0;34m(gt, prob, th)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprecision\u001b[39m(gt, prob, th):\n\u001b[1;32m     36\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m th \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m prob]\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprecision_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1769\u001b[0m, in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprecision_score\u001b[39m(\n\u001b[1;32m   1641\u001b[0m     y_true,\n\u001b[1;32m   1642\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1648\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1649\u001b[0m ):\n\u001b[1;32m   1650\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[1;32m   1651\u001b[0m \n\u001b[1;32m   1652\u001b[0m \u001b[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;124;03m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[1;32m   1768\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1769\u001b[0m     p, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1770\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1771\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1772\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1773\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1774\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1775\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1776\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1777\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1778\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1560\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1560\u001b[0m MCM \u001b[38;5;241m=\u001b[39m \u001b[43mmultilabel_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1561\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1563\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43msamplewise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamplewise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1567\u001b[0m tp_sum \u001b[38;5;241m=\u001b[39m MCM[:, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1568\u001b[0m pred_sum \u001b[38;5;241m=\u001b[39m tp_sum \u001b[38;5;241m+\u001b[39m MCM[:, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:479\u001b[0m, in \u001b[0;36mmultilabel_confusion_matrix\u001b[0;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmultilabel_confusion_matrix\u001b[39m(\n\u001b[1;32m    380\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, samplewise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    381\u001b[0m ):\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute a confusion matrix for each class or sample.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \n\u001b[1;32m    384\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 0.21\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;124;03m            [1, 2]]])\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 479\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m         sample_weight \u001b[38;5;241m=\u001b[39m column_or_1d(sample_weight)\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/sklearn/metrics/_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m---> 85\u001b[0m type_true \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_true\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m y_type \u001b[38;5;241m=\u001b[39m {type_true, type_pred}\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/sklearn/utils/multiclass.py:335\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    332\u001b[0m     _assert_all_finite(y, input_name\u001b[38;5;241m=\u001b[39minput_name)\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontinuous\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix\n\u001b[0;32m--> 335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix  \u001b[38;5;66;03m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/numpy/lib/arraysetops.py:272\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    270\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 272\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/numpy/lib/arraysetops.py:337\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    335\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n\u001b[1;32m    336\u001b[0m mask[:\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aux\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m aux\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcfmM\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43maux\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m aux\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# for complex all NaNs are considered equivalent\u001b[39;00m\n\u001b[1;32m    339\u001b[0m         aux_firstnan \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39misnan(aux), \u001b[38;5;28;01mTrue\u001b[39;00m, side\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.run(train_loader, max_epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "bf92692b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "547205"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b2e6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8409762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a33f1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0fedab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18f030d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3cb78hur) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/group_0</td><td>▁▁</td></tr><tr><td>training/hr</td><td>▁▁</td></tr><tr><td>training/loss</td><td>█▁</td></tr><tr><td>training/ndcg</td><td>▁▁</td></tr><tr><td>training/precision_top</td><td>▁█</td></tr><tr><td>training/recall_top</td><td>▁▁</td></tr><tr><td>training/roc</td><td>▁█</td></tr><tr><td>training/roc_top</td><td>█▁</td></tr><tr><td>validation/hr</td><td>▁</td></tr><tr><td>validation/loss</td><td>▁</td></tr><tr><td>validation/ndcg</td><td>▁</td></tr><tr><td>validation/precision_top</td><td>▁</td></tr><tr><td>validation/recall_top</td><td>▁</td></tr><tr><td>validation/roc</td><td>▁</td></tr><tr><td>validation/roc_top</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/group_0</td><td>0.001</td></tr><tr><td>training/hr</td><td>0.0</td></tr><tr><td>training/loss</td><td>0.84907</td></tr><tr><td>training/ndcg</td><td>0.0</td></tr><tr><td>training/precision_top</td><td>0.66667</td></tr><tr><td>training/recall_top</td><td>1.0</td></tr><tr><td>training/roc</td><td>0.5172</td></tr><tr><td>training/roc_top</td><td>0.5</td></tr><tr><td>validation/hr</td><td>0.61266</td></tr><tr><td>validation/loss</td><td>0.85565</td></tr><tr><td>validation/ndcg</td><td>0.43569</td></tr><tr><td>validation/precision_top</td><td>0.10253</td></tr><tr><td>validation/recall_top</td><td>0.1897</td></tr><tr><td>validation/roc</td><td>0.50921</td></tr><tr><td>validation/roc_top</td><td>0.30762</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">jrs-reco</strong>: <a href=\"https://wandb.ai/tiyuok2023/pytorch-ignite-integration/runs/3cb78hur\" target=\"_blank\">https://wandb.ai/tiyuok2023/pytorch-ignite-integration/runs/3cb78hur</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220628_170750-3cb78hur/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3cb78hur). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.19"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hao/Documents/MA_thesis_u/ncf-torch2/src/jupyter/wandb/run-20220628_173422-1587hfha</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/tiyuok2023/pytorch-ignite-integration/runs/1587hfha\" target=\"_blank\">jrs-reco</a></strong> to <a href=\"https://wandb.ai/tiyuok2023/pytorch-ignite-integration\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ec0b4338ff4b49a84b355445c6ea42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1] 100%|########## [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch[1]  Avg loss: 0.84      Avg ndcg: 0.00  Avg roc: 0.53  Avg roc_top: 0.50       Avg recall: 1.00  Avg precision: 0.67\n"
     ]
    }
   ],
   "source": [
    "wandb_logger = WandBLogger(\n",
    "    project=\"pytorch-ignite-integration\",\n",
    "    name=\"jrs-reco\",\n",
    "    config={\"max_epochs\": EPOCHS,\"batch_size\":BATCH_SIZE},\n",
    "    tags=[\"pytorch-ignite\", \"jrs\"]\n",
    ")\n",
    "\n",
    "to_save = {'model': model}\n",
    "checkpoint_handler = ModelCheckpoint(\n",
    "    wandb_logger.run.dir,\n",
    "    n_saved=2, filename_prefix='best',\n",
    "    score_name=\"roc\",\n",
    "    global_step_transform=global_step_from_engine(trainer)\n",
    ")\n",
    "\n",
    "val_evaluator.add_event_handler(Events.COMPLETED, checkpoint_handler, to_save)\n",
    "\n",
    "\n",
    "'''\n",
    "Attach the Object to the output handlers:\n",
    "1) Log training loss - attach to trainer\n",
    "2) Log validation loss - attach to evaluator\n",
    "3) Log optional Parameters\n",
    "4) Watch the model\n",
    "'''\n",
    "    \n",
    "\n",
    "wandb_logger.attach_output_handler(\n",
    "    trainer,\n",
    "    event_name=Events.ITERATION_COMPLETED,\n",
    "    tag=\"training\",\n",
    "    output_transform=lambda loss: {\"loss\": loss}\n",
    ")\n",
    "\n",
    "wandb_logger.attach_output_handler(\n",
    "    train_evaluator,\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    "    tag=\"training\",\n",
    "    metric_names=['loss',\"roc\", 'hr', 'ndcg','roc_top', 'precision_top','recall_top'],\n",
    "#     hr, ndcg, roc, roc_top, recall, precision = metrics['customEva']\n",
    "    global_step_transform=lambda *_: trainer.state.iteration,\n",
    ")\n",
    "\n",
    "wandb_logger.attach_output_handler(\n",
    "    val_evaluator,\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    "    tag=\"validation\",\n",
    "    metric_names=['loss',\"roc\", 'hr', 'ndcg','roc_top', 'precision_top','recall_top'],\n",
    "    global_step_transform=lambda *_: trainer.state.iteration,\n",
    ")\n",
    "\n",
    "wandb_logger.attach_opt_params_handler(\n",
    "    trainer,\n",
    "    event_name=Events.ITERATION_STARTED,\n",
    "    optimizer=optimizer,\n",
    "    param_name='lr'  # optional\n",
    ")\n",
    "\n",
    "wandb_logger.watch(model)\n",
    "\n",
    "trainer.run(train_loader, max_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea211e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f0bff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44689aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
