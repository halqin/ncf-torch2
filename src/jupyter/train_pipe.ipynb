{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d3cbac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f18dcf387f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../src')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import config\n",
    "import data_process.neg_sample as ng_sample\n",
    "from sklearn import metrics, preprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import evaluate_entity\n",
    "from model_entity import EntityCat\n",
    "from data_utils import CatData\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import time\n",
    "from utils.constants import DEFAULT_USER_COL,DEFAULT_ITEM_COL,DEFAULT_RATING_COL, DEFAULT_TIMESTAMP_COL\n",
    "# import argparse\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0f7c725",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2**10\n",
    "EPOCHS  = 10\n",
    "TOP_K = 10\n",
    "NEG_TEST = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c9d49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbff8d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e094616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train1  = ng_sample.read_feather(\"../../data/jobs/leave_one_train.csv\").iloc[:100,]\n",
    "# df_train2 = pd.read_feather(\"../../data/jobs/leave_one_train_neg\").iloc[:100,]\n",
    "# df_test_ori = pd.read_feather(\"../../data/jobs/test_pos_neg\").iloc[:101,]\n",
    "# df_all_features = pd.read_csv('../../data/jobs/merged_sub_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "625d8989",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1  = ng_sample.read_feather(\"../../data/jobs/leave_one_train.csv\")\n",
    "df_train2 = pd.read_feather(\"../../data/jobs/leave_one_train_neg\")\n",
    "df_test_ori = pd.read_feather(\"../../data/jobs/test_pos_neg\")\n",
    "df_all_features = pd.read_csv('../../data/jobs/merged_sub_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9255ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1['rating'] = 1\n",
    "df_train_all = pd.concat([df_train1, df_train2], axis=0)\n",
    "df_train_all['flag'] = 1\n",
    "df_test_ori['flag'] = 0\n",
    "df_all = pd.concat([df_train_all, df_test_ori], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bc6348",
   "metadata": {},
   "source": [
    "user features: \n",
    "       'WindowID_user', 'Split', 'City',\n",
    "       'State', 'Country', 'Zip_user', 'DegreeType', 'Major', 'GraduationDate',\n",
    "       'WorkHistoryCount', 'TotalYearsExperience', 'CurrentlyEmployed',\n",
    "       'ManagedOthers', 'ManagedHowMany',\n",
    "       \n",
    "job features: \n",
    "       'WindowID_job', 'City_job',\n",
    "       'State_job', 'Country_job', 'Zip_job', 'StartDate', 'EndDate',"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0715af10",
   "metadata": {},
   "source": [
    "### Choose the features for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23a67e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = ['City']\n",
    "user_features_extend = [DEFAULT_USER_COL] + user_features\n",
    "\n",
    "item_features = ['City_job']\n",
    "item_features_extend =[DEFAULT_ITEM_COL] + item_features\n",
    "\n",
    "base_features = [DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22ad8b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_filter(df_data, name_col):\n",
    "    df_uni=df_data[~(df_data[name_col].duplicated())].reset_index(drop=True)\n",
    "    return df_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b30a460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_merge(list_f, df_all, df_all_f, default_x_col):\n",
    "    df_x_features = df_all_f[list_f]\n",
    "    df_x_unique = unique_filter(df_x_features, default_x_col)\n",
    "    df_merge_x = df_all.merge(df_x_unique, how='left', on=[default_x_col])\n",
    "    return df_merge_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7acbca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_item_merge(mode, df_all, df_all_features, feature_list):\n",
    "    if mode =='user':\n",
    "        df_merge_x = feature_merge(feature_list, df_all, df_all_features,\\\n",
    "                                      DEFAULT_USER_COL)\n",
    "    if mode == 'item':\n",
    "        df_merge_x = feature_merge(feature_list, df_all, df_all_features, \\\n",
    "                                   DEFAULT_ITEM_COL)\n",
    "\n",
    "    return df_merge_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0e7f502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_merge(df_all, df_all_features, f_list_user, f_list_item):\n",
    "    df_merge_user = feature_merge(f_list_user, df_all, df_all_features, \\\n",
    "                                  DEFAULT_USER_COL)\n",
    "    df_merge_item = feature_merge(f_list_item, df_all, df_all_features, \\\n",
    "                                  DEFAULT_ITEM_COL)\n",
    "    df_merge_x = pd.concat([df_merge_user[f_list_user], \\\n",
    "                             df_merge_item[f_list_item]], axis=1)\n",
    "    df_merge_x[DEFAULT_RATING_COL] = df_all[DEFAULT_RATING_COL]\n",
    "    assert df_all.shape[0] == df_merge_x.shape[0], \"wrong merge\"\n",
    "    return df_merge_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0be3c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mix_merge = mix_merge(df_all, df_all_features, user_features_extend, item_features_extend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7005bc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fae91863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_encode(df_data, list_f):\n",
    "    for f in list_f:\n",
    "        df_data[f] = le.fit_transform(df_data[f].astype('category').cat.codes.values)\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9370037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_code = df_mix_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5192e4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_encode = cat_encode(df_mix_merge, features_to_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2b69e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_encode[DEFAULT_RATING_COL] = df_all[DEFAULT_RATING_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78915b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_all_encode[df_all.flag==1]\n",
    "df_test = df_all_encode[df_all.flag==0]\n",
    "\n",
    "# df_train=df_train.drop(['flag'], axis=1)\n",
    "# df_test=df_test.drop(['flag'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8e49d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_train = [DEFAULT_USER_COL, DEFAULT_ITEM_COL]+ user_features + item_features +[DEFAULT_RATING_COL]\n",
    "df_train = df_train[features_to_train]\n",
    "df_test = df_test[features_to_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a896e00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CityCity_job'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb_cf = \"-\".join(user_features)+'-'.join(item_features)\n",
    "tb_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "136f85ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train[features_to_train]\n",
    "df_test=df_test[features_to_train]\n",
    "\n",
    "num_feature=[]\n",
    "features_to_train.remove(DEFAULT_RATING_COL)\n",
    "# label_name = DEFAULT_RATING_COL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d98e3845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np_train = df_train.values\n",
    "np_test = df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fb2a567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f18d56595b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6dc4eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2**25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "269226d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CatData(np_train)\n",
    "test_dataset = CatData(np_test) \n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0,  worker_init_fn=seed_worker,generator=g)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=NEG_TEST+1, shuffle=False, num_workers=0,worker_init_fn=seed_worker,generator=g )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c357eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = []\n",
    "for c in features_to_train:\n",
    "    num_unique_values = int(df_all_encode[c].nunique())\n",
    "    embed_dim = int(min(np.ceil(num_unique_values/2), 50))\n",
    "    embedding_size.append([num_unique_values, embed_dim])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8694e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EntityCat(embedding_size = embedding_size, num_numerical_cols = len(num_feature),\n",
    "               output_size = 2)\n",
    "model.to(device)\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f38e4bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EntityCat(\n",
      "  (all_embeddings): ModuleList(\n",
      "    (0): Embedding(89946, 50)\n",
      "    (1): Embedding(139292, 50)\n",
      "    (2): Embedding(6296, 50)\n",
      "    (3): Embedding(5405, 50)\n",
      "  )\n",
      "  (embedding_dropout): Dropout(p=0.4, inplace=False)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.4, inplace=False)\n",
      "    (3): Linear(in_features=100, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f71833ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0/10: ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:14<00:00, 14.12s/it]\n",
      "100%|████████████████████████████████████| 74091/74091 [04:51<00:00, 254.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time elapse/epoch: 00: 05: 05\n",
      "test_loss:0.9422452772290033\n",
      "test_HR:0.10564036117747094            \n",
      "test_NDCG:0.047514795444033905\n",
      "test_ROC:0.5113564400534478            \n",
      "test_ROC@k:0\n",
      "EPOCH 1/10: ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:13<00:00, 13.23s/it]\n",
      " 91%|████████████████████████████████▋   | 67265/74091 [04:26<00:27, 251.95it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m avg_loss_train, \u001b[38;5;241m*\u001b[39mb \u001b[38;5;241m=\u001b[39m run_one_epoch(model,epoch,writer, data_loader\u001b[38;5;241m=\u001b[39mtrain_loader, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     54\u001b[0m avg_loss_test, avg_HR_test, avg_NDCG_test, avg_ROC_test, avg_ROC_top_test, avg_Recall_test, avg_Precision_test \\\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;241m=\u001b[39m \u001b[43mrun_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe time elapse/epoch: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     59\u001b[0m       time\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH: \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM: \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m, time\u001b[38;5;241m.\u001b[39mgmtime(elapsed_time)))\n",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, epoch_index, writer, data_loader, is_train)\u001b[0m\n\u001b[1;32m     20\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     21\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     23\u001b[0m HR_1batch, NDCG_1batch, ROC_1batch, ROC_top1batch, Recall_1batch, Precision_1batch\u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m---> 24\u001b[0m \u001b[43mevaluate_entity\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcat_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTOP_K\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m HR\u001b[38;5;241m.\u001b[39mappend(HR_1batch)\n\u001b[1;32m     26\u001b[0m NDCG\u001b[38;5;241m.\u001b[39mappend( NDCG_1batch)\n",
      "File \u001b[0;32m~/Documents/MA_thesis_u/ncf-torch2/src/jupyter/../../src/evaluate_entity.py:54\u001b[0m, in \u001b[0;36mmetrics\u001b[0;34m(cat_data, predictions, label, top_k, is_train, threshold)\u001b[0m\n\u001b[1;32m     52\u001b[0m     ROC_top1batch \u001b[38;5;241m=\u001b[39m roc(label[indices]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), y_score\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     53\u001b[0m     recall_1batch \u001b[38;5;241m=\u001b[39m recall(label[indices]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), y_score\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), threshold)\n\u001b[0;32m---> 54\u001b[0m     precision_1batch \u001b[38;5;241m=\u001b[39m \u001b[43mprecision\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m HR_1batch, NDCG_1batch, ROC_1batch, ROC_top1batch, recall_1batch, precision_1batch\n",
      "File \u001b[0;32m~/Documents/MA_thesis_u/ncf-torch2/src/jupyter/../../src/evaluate_entity.py:33\u001b[0m, in \u001b[0;36mprecision\u001b[0;34m(gt, prob, th)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprecision\u001b[39m(gt, prob, th):\n\u001b[0;32m---> 33\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m th \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m prob]\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m precision_score(gt, y_pred, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/MA_thesis_u/ncf-torch2/src/jupyter/../../src/evaluate_entity.py:33\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprecision\u001b[39m(gt, prob, th):\n\u001b[0;32m---> 33\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mth\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m prob]\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m precision_score(gt, y_pred, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%m-%d_%H-%M-%S')\n",
    "writer = SummaryWriter('runs/trainer_{}_{}'.format(tb_cf, timestamp))\n",
    "plot_n_batch = 10\n",
    "\n",
    "\n",
    "\n",
    "def run_one_epoch(model, epoch_index, writer, data_loader=train_loader, is_train=True):\n",
    "    running_loss = 0.\n",
    "    avg_loss = 0.\n",
    "    HR, NDCG, ROC, ROC_top, Recall, Precision = [], [], [], [], [], []\n",
    "    \n",
    "    for batch, (cat_data, label) in enumerate(tqdm.tqdm(data_loader)):\n",
    "        cat_data = cat_data.to(device)\n",
    "        label = label.to(device).float()\n",
    "        prediction = model(cat_data)[:,1]\n",
    "        loss = loss_function(prediction, label)\n",
    "        running_loss += loss.item()\n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        HR_1batch, NDCG_1batch, ROC_1batch, ROC_top1batch, Recall_1batch, Precision_1batch= \\\n",
    "        evaluate_entity.metrics(cat_data, prediction, label, TOP_K, is_train)\n",
    "        HR.append(HR_1batch)\n",
    "        NDCG.append( NDCG_1batch)\n",
    "        ROC.append( ROC_1batch)\n",
    "        ROC_top.append(ROC_top1batch)\n",
    "        Recall.append(Recall_1batch)\n",
    "        Precision.append(Precision_1batch)\n",
    "        \n",
    "    avg_loss = running_loss / (batch +1)  \n",
    " \n",
    "    avg_HR = np.mean(HR)\n",
    "    avg_NDCG = np.mean(NDCG)\n",
    "    avg_ROC = np.mean(ROC)\n",
    "    try:\n",
    "        avg_ROC_top = np.mean(ROC_top)\n",
    "    except:\n",
    "        avg_ROC_top = 0\n",
    "    avg_recall = np.mean(Recall)\n",
    "    avg_precision = np.mean(Precision)\n",
    "    return avg_loss, avg_HR, avg_NDCG , avg_ROC, avg_ROC_top, avg_recall, avg_precision\n",
    "\n",
    " \n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}/{}: ---------'.format(epoch, EPOCHS))\n",
    "    start_time = time.time()\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    " \n",
    "    model.train(True)\n",
    "    avg_loss_train, *b = run_one_epoch(model,epoch,writer, data_loader=train_loader, is_train=True)\n",
    "    model.train(False)\n",
    "    avg_loss_test, avg_HR_test, avg_NDCG_test, avg_ROC_test, avg_ROC_top_test, avg_Recall_test, avg_Precision_test \\\n",
    "    = run_one_epoch(model,epoch, writer, data_loader=test_loader, is_train=False)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"The time elapse/epoch: \" +\n",
    "          time.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time)))\n",
    "    \n",
    "#     print(f\"train_loss:{avg_loss_train}\\ntrain_HR:{avg_HR_train}\\\n",
    "#             \\ntrain_NDCG:{avg_NDCG_train}\\ntrain_ROC:{avg_ROC_train}\\ntrain_ROC_top:{avg_ROC_top_train})\n",
    "    print(f\"test_loss:{avg_loss_test}\\ntest_HR:{avg_HR_test}\\\n",
    "            \\ntest_NDCG:{avg_NDCG_test}\\ntest_ROC:{avg_ROC_test}\\\n",
    "            \\ntest_ROC@k:{avg_ROC_top_test}\")\n",
    " \n",
    "    writer.add_scalars('Loss',\n",
    "                    { 'Train' : avg_loss_train, 'Test' : avg_loss_test },\n",
    "                    epoch )\n",
    "\n",
    "#    writer.add_scalars('HitRate',\n",
    "#                 { 'Train' : avg_HR_train, 'Test' : avg_HR_test },\n",
    "#                 epoch)\n",
    "    \n",
    "#     writer.add_scalars('NDCG',\n",
    "#             { 'Train' : avg_NDCG_train, 'Test' : avg_NDCG_test },\n",
    "#             epoch)\n",
    "    \n",
    "#     writer.add_scalars('ROC',\n",
    "#             { 'Train' : avg_ROC_train, 'Test' : avg_ROC_test },\n",
    "#             epoch)\n",
    "\n",
    "# # model_path = 'runs/model_{}'.format(timestamp)\n",
    "# # torch.save(model.state_dict(), model_path)\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e602b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    ">>> from sklearn.metrics import average_precision_score,recall_score,precision_recall_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca8db7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_true = [0, 0, 0, 1]\n",
    "y_scores = [0.261, 0.21, 0.161, 0.361]\n",
    "# average_precision_score(y_true, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dd93a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(np.unique(y_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd5d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision_recall_curve(y_true, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df829226",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [1 if y>0.5 else 0 for y in y_scores ]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc5fc92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recall_score(y_true, y_pred, average='binary', zero_division=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dac0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = tp/tp+fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3e0ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = tp/tp+fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb015a87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
