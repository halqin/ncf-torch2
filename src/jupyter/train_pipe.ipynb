{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d3cbac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hao/.pyenv/versions/3.6.15/envs/torch-cpu5/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10ca56180>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../src')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "from hydra import initialize, compose\n",
    "import pathlib\n",
    "# import config\n",
    "\n",
    "import data_process.neg_sample as ng_sample\n",
    "from data_process.utils import mix_merge\n",
    "from data_process.data_split import data_split_user\n",
    "from evaluate_entity import CustomHR, CustomNDCG, CustomRoc, CustomRoctop, CustomRecall_top, CustomPrecision_top\n",
    "from model_entity import EntityCat\n",
    "from data_utils import CatData\n",
    "from utils.constants import DEFAULT_USER_COL,DEFAULT_ITEM_COL,DEFAULT_RATING_COL, DEFAULT_TIMESTAMP_COL\n",
    "\n",
    "\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, recall_score, precision_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# import argparse\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "452234bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Engine, Events, create_supervised_trainer, create_supervised_evaluator, RemovableEventHandle\n",
    "from ignite.metrics import Accuracy, Loss, Metric\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "from ignite.exceptions import NotComputableError\n",
    "from ignite.metrics.metric import sync_all_reduce, reinit__is_reduced\n",
    "from ignite.contrib.handlers.tqdm_logger import ProgressBar\n",
    "# from ignite.contrib.handlers import TensorboardLogger \n",
    "from ignite.contrib.handlers.wandb_logger import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c9d49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1c783c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path=\"../conf\"):\n",
    "    cfg = compose(config_name=\"config\", overrides=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3fca5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type =='cpu':\n",
    "    BATCH_SIZE = cfg.params.batch_size_cpu\n",
    "    EPOCHS  = cfg.params.epochs_cpu\n",
    "else:\n",
    "    BATCH_SIZE = cfg.params.batch_size_gpu\n",
    "    EPOCHS  = cfg.params.epochs_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e094616",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type == 'cpu':\n",
    "    use_amp=False\n",
    "    df_train_pos  = ng_sample.read_feather(pathlib.Path(cfg.path.root, cfg.file.train_pos))\n",
    "    df_train_neg = pd.read_feather(pathlib.Path(cfg.path.root, cfg.file.train_neg))\n",
    "    df_test_ori = pd.read_feather(pathlib.Path(cfg.path.root, cfg.file.test)).iloc[:202,]\n",
    "    df_all_features = pd.read_csv(pathlib.Path(cfg.path.root, cfg.file.all_features))\n",
    "    df_train_pos = df_train_pos.sort_values(by=[DEFAULT_USER_COL]).iloc[:100,].reset_index(drop=True)\n",
    "    df_train_neg = df_train_neg.sort_values(by=[DEFAULT_USER_COL]).iloc[:100*cfg.params.neg_train,].reset_index(drop=True)\n",
    "else:\n",
    "    use_amp=True\n",
    "    df_train_pos  = ng_sample.read_feather(pathlib.Path(cfg.path.root, cfg.file.train_pos))\n",
    "    df_train_neg = pd.read_feather(pathlib.Path(cfg.path.root, cfg.file.train_neg))\n",
    "    df_test_ori = pd.read_feather(pathlib.Path(cfg.path.root, cfg.file.test))\n",
    "    df_all_features = pd.read_csv(pathlib.Path(cfg.path.root, cfg.file.all_features))\n",
    "    df_train_pos = df_train_pos.sort_values(by=[DEFAULT_USER_COL]).reset_index(drop=True)\n",
    "    df_train_neg = df_train_neg.sort_values(by=[DEFAULT_USER_COL]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97918f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pos[DEFAULT_RATING_COL] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9b8c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_index(df1, df2):\n",
    "    df2.index = df2.index//cfg.params.neg_train\n",
    "    return pd.concat([df1, df2], axis=0).sort_index(kind='mregesort').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "103e06ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all = concat_index(df_train_pos, df_train_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9255ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all['flag'] = 1\n",
    "df_test_ori['flag'] = 0\n",
    "df_all = pd.concat([df_train_all, df_test_ori], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bc6348",
   "metadata": {},
   "source": [
    "user features: \n",
    "       'WindowID_user', 'Split', 'City',\n",
    "       'State', 'Country', 'Zip_user', 'DegreeType', 'Major', 'GraduationDate',\n",
    "       'WorkHistoryCount', 'TotalYearsExperience', 'CurrentlyEmployed',\n",
    "       'ManagedOthers', 'ManagedHowMany',\n",
    "       \n",
    "job features: \n",
    "       'WindowID_job', 'City_job',\n",
    "       'State_job', 'Country_job', 'Zip_job', 'StartDate', 'EndDate',"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804e3ff2",
   "metadata": {},
   "source": [
    "# Adding the Sbert embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "789216af",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title_emb = pd.read_feather(pathlib.Path(cfg.path.root, cfg.file.title_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "394c56f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title_emb.rename(columns={'item_id':DEFAULT_ITEM_COL}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "48115dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.merge(df_all, job_title_emb[['Title_em', 'itemid']], how='left', on=[DEFAULT_ITEM_COL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "939ed0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userid', 'itemid', 'rating', 'flag', 'Title_em'], dtype='object')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0715af10",
   "metadata": {},
   "source": [
    "### Choose the features and process data for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "23a67e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = ['City']\n",
    "user_features_extend = [DEFAULT_USER_COL] + user_features\n",
    "\n",
    "item_features = ['City_job']\n",
    "item_features_extend =[DEFAULT_ITEM_COL] + item_features\n",
    "\n",
    "base_features = [DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d0be3c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mix_merge = mix_merge(df_all , df_all_features, user_features_extend, item_features_extend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c8084733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cat_encode(df_data, list_f, encoder):\n",
    "    for f in list_f:\n",
    "        df_data[f] = encoder.fit_transform(df_data[f].astype('category').cat.codes.values)\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3f75839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _embedding_dimension(df_all_encode, features_to_train, max_dim=50):\n",
    "\n",
    "    embedding_size = []\n",
    "    features_to_em = [i for i in features_to_train if i !=DEFAULT_RATING_COL]\n",
    "    for c in features_to_em:\n",
    "        num_unique_values = int(df_all_encode[c].nunique())\n",
    "        embed_dim = int(min(np.ceil(num_unique_values/2), max_dim))\n",
    "        embedding_size.append([num_unique_values, embed_dim])  \n",
    "    return embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8a26ae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(df_mix_merge, features_to_code, features_to_train, max_dim=50):\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    df_all_encode = _cat_encode(df_mix_merge, features_to_code, encoder)\n",
    "    df_train = df_all_encode[df_all.flag==1]\n",
    "    df_test = df_all_encode[df_all.flag==0]\n",
    "    df_train = df_train[features_to_train]\n",
    "    df_test = df_test[features_to_train]\n",
    "    embedding_size = _embedding_dimension(df_all_encode, features_to_train, max_dim)\n",
    "    return df_train, df_test, embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6eb03d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feature=[]\n",
    "features_to_code = df_mix_merge.columns\n",
    "features_to_train = [DEFAULT_USER_COL, DEFAULT_ITEM_COL]+ user_features + item_features +[DEFAULT_RATING_COL]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9370037a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of embedding layers:[[36, 18], [413, 50], [35, 18], [230, 50]]\n"
     ]
    }
   ],
   "source": [
    "df_train,  df_test, embedding_size = encode_data(df_mix_merge, features_to_code, features_to_train, max_dim=cfg.params.emb_dim)\n",
    "\n",
    "print(f'The size of embedding layers:{embedding_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98032331",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_split, df_val_split = data_split_user(df_train, val_size=0.2)\n",
    "\n",
    "np_train = df_train_split.values\n",
    "np_val = df_val_split.values\n",
    "np_test = df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fb2a567",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1283d7af8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb16f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CatData(np_train)\n",
    "val_dataset = CatData(np_val)\n",
    "test_dataset = CatData(np_test) \n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0,  worker_init_fn=seed_worker,generator=g)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False, num_workers=0,  worker_init_fn=seed_worker,generator=g)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=cfg.params.neg_test+1, shuffle=False, num_workers=0,worker_init_fn=seed_worker,generator=g )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8694e807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EntityCat(\n",
       "  (all_embeddings): ModuleList(\n",
       "    (0): Embedding(36, 18)\n",
       "    (1): Embedding(413, 50)\n",
       "    (2): Embedding(35, 18)\n",
       "    (3): Embedding(230, 50)\n",
       "  )\n",
       "  (embedding_dropout): Dropout(p=0.4, inplace=False)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=136, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EntityCat(embedding_size = embedding_size, num_numerical_cols = len(num_feature),\n",
    "               output_size = 2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7098e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg.params.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f38e4bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EntityCat(\n",
      "  (all_embeddings): ModuleList(\n",
      "    (0): Embedding(36, 18)\n",
      "    (1): Embedding(413, 50)\n",
      "    (2): Embedding(35, 18)\n",
      "    (3): Embedding(230, 50)\n",
      "  )\n",
      "  (embedding_dropout): Dropout(p=0.4, inplace=False)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=136, out_features=100, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.4, inplace=False)\n",
      "    (3): Linear(in_features=100, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686edeec",
   "metadata": {},
   "source": [
    "## Model the training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9670b731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_trans_loss(output):\n",
    "    return output['y_pred'], output['label']\n",
    "\n",
    "val_metrics_train = {\n",
    "    'auc': CustomRoc(),\n",
    "    \"loss\": Loss(criterion, output_transform=output_trans_loss)\n",
    "}\n",
    "\n",
    "val_metrics_test = {\n",
    "    'hr': CustomHR(),\n",
    "    'ndcg': CustomNDCG(),\n",
    "    'auc': CustomRoc(),\n",
    "    'roc_top': CustomRoctop(),\n",
    "    'recall_top': CustomRecall_top(threshold=0.5),\n",
    "    'precision_top': CustomPrecision_top(threshold=0.5),\n",
    "    \"loss\": Loss(criterion, output_transform=output_trans_loss)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df93a20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ignite.engine.events.RemovableEventHandle at 0x136b1af98>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "def train_step(engine, batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch[0].to(device), batch[1].to(device)\n",
    "    with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "        y_pred = model(x)[:,1]\n",
    "        loss = criterion(y_pred, y.float())\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    return loss.item()\n",
    "\n",
    "def validation_step(engine, batch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, label = batch[0].to(device), batch[1].to(device)\n",
    "        y_pred = model(x)[:,1]\n",
    "        label=label.float()\n",
    "        return {'label':label, 'y_pred':y_pred}\n",
    "\n",
    "def test_step(engine, batch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, label = batch[0].to(device), batch[1].to(device)\n",
    "        y_pred = model(x)[:,1]\n",
    "        label=label.float()\n",
    "        y_pred_top, indices = torch.topk(y_pred, engine.state.topk)\n",
    "        y_pred_top = y_pred_top.detach().cpu().numpy()\n",
    "        reco_item = torch.take(x[:,1], indices).cpu().numpy().tolist()\n",
    "        pos_item = x[0,1].cpu().numpy().tolist()  # ground truth, item id\n",
    "        label_top = label[indices].cpu().numpy()\n",
    "        return {'pos_item':pos_item, 'reco_item':reco_item, 'y_pred_top':y_pred_top, 'label_top':label_top, 'label':label, 'y_pred':y_pred}\n",
    "\n",
    "trainer = Engine(train_step)\n",
    "\n",
    "train_evaluator = Engine(validation_step)\n",
    "# train_evaluator.state_dict_user_keys.append('topk')\n",
    "\n",
    "val_evaluator = Engine(validation_step)\n",
    "# val_evaluator.state_dict_user_keys.append('topk')\n",
    "\n",
    "test_evaluator = Engine(test_step)\n",
    "test_evaluator.state_dict_user_keys.append('topk')\n",
    "\n",
    "# @val_evaluator.on(Events.STARTED)\n",
    "# def init_user_value():\n",
    "#     val_evaluator.state.topk=3\n",
    "    \n",
    "# @train_evaluator.on(Events.STARTED)\n",
    "# def init_user_value():\n",
    "#     train_evaluator.state.topk=3\n",
    "\n",
    "@train_evaluator.on(Events.STARTED)\n",
    "def init_user_value():\n",
    "    test_evaluator.state.topk=cfg.params.topk\n",
    "    \n",
    "    \n",
    "# Attach metrics to the evaluators\n",
    "for name, metric in val_metrics_train.items():\n",
    "    metric.attach(train_evaluator, name)\n",
    "\n",
    "for name, metric in val_metrics_train.items():\n",
    "    metric.attach(val_evaluator, name)\n",
    "\n",
    "    \n",
    "for name, metric in val_metrics_test.items():\n",
    "    metric.attach(test_evaluator, name)\n",
    "    \n",
    "# Eearly_stop \n",
    "def score_function(engine):\n",
    "    val_loss = engine.state.metrics['auc']\n",
    "    return val_loss\n",
    "\n",
    "Eearly_stop_handler = EarlyStopping(patience=cfg.params.patience, score_function=score_function, trainer=trainer)\n",
    "val_evaluator.add_event_handler(Events.COMPLETED, Eearly_stop_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8b9d6ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    train_evaluator.run(train_loader)\n",
    "    metrics = train_evaluator.state.metrics\n",
    "    auc = metrics['auc']\n",
    "    loss = metrics['loss']\n",
    "    print(f'Training Results- Epoch[{trainer.state.epoch}]  Avg loss: {loss:.2f} \\\n",
    "          Avg auc:{auc:.2f}')\n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    val_evaluator.run(val_loader)\n",
    "    metrics = val_evaluator.state.metrics\n",
    "    auc = metrics['auc']\n",
    "    loss = metrics['loss']\n",
    "    print(f'Validation Results- Epoch[{trainer.state.epoch}]  Avg loss: {loss:.2f} \\\n",
    "          Avg auc:{auc:.2f}')\n",
    "\n",
    "    \n",
    "@trainer.on(Events.COMPLETED)\n",
    "def log_test_results(trainer):\n",
    "    test_evaluator.run(test_loader)\n",
    "    metrics = test_evaluator.state.metrics\n",
    "    hr = metrics['hr']\n",
    "    ndcg = metrics['ndcg']\n",
    "    auc = metrics['auc']\n",
    "    roc_top = metrics['roc_top']\n",
    "    recall = metrics['recall_top']\n",
    "    precision = metrics['precision_top']\n",
    "    loss = metrics['loss']\n",
    "    print(f\"Test Results - Epoch[{trainer.state.epoch}]  Avg loss: {loss:.2f} \\\n",
    "     Avg ndcg: {ndcg:.2f}  Avg auc: {auc:.2f}  Avg auc_top: {roc_top:.2f} \\\n",
    "      Avg recall: {recall:.2f}  Avg precision: {precision:.2f}\")\n",
    "\n",
    "pbar = ProgressBar(persist=False)\n",
    "# pbar.attach(trainer)\n",
    "pbar.attach(trainer)\n",
    "# from ignite.handlers import Timer\n",
    "# timer = Timer(average=True)\n",
    "# timer.attach(trainer,\n",
    "#              start=Events.STARTED,\n",
    "#              resume=Events.EPOCH_STARTED,\n",
    "#              pause=Events.EPOCH_COMPLETED,\n",
    "#              step=Events.EPOCH_COMPLETED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af997b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.run(train_loader, max_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b18f030d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.12.20 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.19"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/hao/Documents/MA_thesis/ncf-torch2/src/jupyter/wandb/run-20220630_230554-25opvret</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/tiyuok2023/pytorch-jrs/runs/25opvret\" target=\"_blank\">City-City_job</a></strong> to <a href=\"https://wandb.ai/tiyuok2023/pytorch-jrs\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hao/.pyenv/versions/3.6.15/envs/torch-cpu5/lib/python3.6/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "/Users/hao/.pyenv/versions/3.6.15/envs/torch-cpu5/lib/python3.6/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results- Epoch[1]  Avg loss: 0.62           Avg auc:1.00\n",
      "Validation Results- Epoch[1]  Avg loss: 0.71           Avg auc:0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hao/.pyenv/versions/3.6.15/envs/torch-cpu5/lib/python3.6/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results- Epoch[2]  Avg loss: 0.62           Avg auc:1.00\n",
      "Validation Results- Epoch[2]  Avg loss: 0.71           Avg auc:0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hao/.pyenv/versions/3.6.15/envs/torch-cpu5/lib/python3.6/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results- Epoch[3]  Avg loss: 0.62           Avg auc:1.00\n",
      "Validation Results- Epoch[3]  Avg loss: 0.71           Avg auc:0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/20]: [21/21] 100%|██████████ [00:00<00:00]2022-06-30 23:05:59,255 ignite.handlers.early_stopping.EarlyStopping INFO: EarlyStopping: Stop training\n",
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results- Epoch[4]  Avg loss: 0.62           Avg auc:1.00\n",
      "Validation Results- Epoch[4]  Avg loss: 0.71           Avg auc:0.79\n",
      "Test Results - Epoch[4]  Avg loss: 0.91      Avg ndcg: 0.22  Avg auc: 0.78  Avg auc_top: 0.33       Avg recall: 0.50  Avg precision: 0.05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/group_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test/auc</td><td>▁</td></tr><tr><td>test/hr</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/ndcg</td><td>▁</td></tr><tr><td>test/precision_top</td><td>▁</td></tr><tr><td>test/recall_top</td><td>▁</td></tr><tr><td>test/roc_top</td><td>▁</td></tr><tr><td>training/auc</td><td>▁▁▁▁</td></tr><tr><td>training/loss</td><td>▅█▆▁▁▅▂▁▁▄▂▅▅▁▁▁▁▁▁▁▁▂▅▁▁▁▅▁▁▁▅▅▁▃▁█▁▁▁▁</td></tr><tr><td>validation/auc</td><td>█▇▅▁</td></tr><tr><td>validation/loss</td><td>▁▄█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/group_0</td><td>0.001</td></tr><tr><td>test/auc</td><td>0.78</td></tr><tr><td>test/hr</td><td>0.5</td></tr><tr><td>test/loss</td><td>0.91185</td></tr><tr><td>test/ndcg</td><td>0.21534</td></tr><tr><td>test/precision_top</td><td>0.05</td></tr><tr><td>test/recall_top</td><td>0.5</td></tr><tr><td>test/roc_top</td><td>0.33333</td></tr><tr><td>training/auc</td><td>1.0</td></tr><tr><td>training/loss</td><td>0.61898</td></tr><tr><td>validation/auc</td><td>0.78809</td></tr><tr><td>validation/loss</td><td>0.71224</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">City-City_job</strong>: <a href=\"https://wandb.ai/tiyuok2023/pytorch-jrs/runs/25opvret\" target=\"_blank\">https://wandb.ai/tiyuok2023/pytorch-jrs/runs/25opvret</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220630_230554-25opvret/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config_dict = dict(cfg.params)\n",
    "config_dict['Features']='-'.join(user_features+item_features)\n",
    "wandb_logger = WandBLogger(\n",
    "    project=\"pytorch-jrs\",\n",
    "    name=\"-\".join(user_features)+'-'+'-'.join(item_features),\n",
    "    config=config_dict,\n",
    "    tags=[\"entity\", \"jrs\"]\n",
    ")\n",
    "\n",
    "to_save = {'model': model}\n",
    "checkpoint_handler = ModelCheckpoint(\n",
    "    wandb_logger.run.dir,\n",
    "    n_saved=2, filename_prefix='best',\n",
    "    score_name=\"auc\",\n",
    "    global_step_transform=global_step_from_engine(trainer)\n",
    ")\n",
    "\n",
    "val_evaluator.add_event_handler(Events.COMPLETED, checkpoint_handler, to_save)\n",
    "\n",
    "    \n",
    "wandb_logger.attach_output_handler(\n",
    "    trainer,\n",
    "    event_name=Events.ITERATION_COMPLETED,\n",
    "    tag=\"training\",\n",
    "    output_transform=lambda loss: {\"loss\": loss}\n",
    ")\n",
    "\n",
    "wandb_logger.attach_output_handler(\n",
    "    train_evaluator,\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    "    tag=\"training\",\n",
    "    metric_names=['loss','auc'],\n",
    "    global_step_transform=lambda *_: trainer.state.iteration,\n",
    ")\n",
    "\n",
    "wandb_logger.attach_output_handler(\n",
    "    val_evaluator,\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    "    tag=\"validation\",\n",
    "    metric_names=['loss',\"auc\"],\n",
    "    global_step_transform=lambda *_: trainer.state.iteration,\n",
    ")\n",
    "\n",
    "\n",
    "wandb_logger.attach_output_handler(\n",
    "    test_evaluator,\n",
    "    event_name=Events.COMPLETED,\n",
    "    tag=\"test\",\n",
    "    metric_names=['loss',\"auc\", 'hr', 'ndcg', 'roc_top', 'recall_top', 'precision_top'],\n",
    "    global_step_transform=lambda *_: trainer.state.iteration,\n",
    ")\n",
    "\n",
    "\n",
    "wandb_logger.attach_opt_params_handler(\n",
    "    trainer,\n",
    "    event_name=Events.ITERATION_STARTED,\n",
    "    optimizer=optimizer,\n",
    "    param_name='lr'  # optional\n",
    ")\n",
    "\n",
    "# wandb_logger.watch(model) \n",
    "\n",
    "trainer.run(train_loader, max_epochs=EPOCHS)\n",
    "wandb_logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea211e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f0bff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44689aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
