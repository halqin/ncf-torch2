{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d3cbac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7feeeb7e9430>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../src')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "from hydra import initialize, compose\n",
    "import pathlib\n",
    "# import config\n",
    "\n",
    "import data_process.neg_sample as ng_sample\n",
    "from data_process.utils import mix_merge\n",
    "from data_process.data_split import data_split_user\n",
    "from metrics.evaluate_ignite import CustomHR, CustomNDCG, CustomAuc_top, CustomAuc, CustomRecall_top, CustomPrecision_top\n",
    "from model_entity import EntityCat, EntityCat_sbert\n",
    "from data_utils import CatData\n",
    "from utils.constants import DEFAULT_USER_COL,DEFAULT_ITEM_COL,DEFAULT_RATING_COL, DEFAULT_TIMESTAMP_COL\n",
    "\n",
    "\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, recall_score, precision_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# import argparse\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "452234bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Engine, Events, create_supervised_trainer, create_supervised_evaluator, RemovableEventHandle\n",
    "from ignite.metrics import Accuracy, Loss, Metric\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "from ignite.exceptions import NotComputableError\n",
    "from ignite.metrics.metric import sync_all_reduce, reinit__is_reduced\n",
    "from ignite.contrib.handlers.tqdm_logger import ProgressBar\n",
    "# from ignite.contrib.handlers import TensorboardLogger \n",
    "from ignite.contrib.handlers.wandb_logger import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c9d49c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c783c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path=\"../conf\"):\n",
    "    cfg = compose(config_name=\"config\", overrides=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3fca5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type =='cpu':\n",
    "    BATCH_SIZE = cfg.params.batch_size_cpu\n",
    "    EPOCHS  = cfg.params.epochs_cpu\n",
    "else:\n",
    "    BATCH_SIZE = cfg.params.batch_size_gpu\n",
    "    EPOCHS  = cfg.params.epochs_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e094616",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type != 'cpu':\n",
    "    use_amp=False\n",
    "    df_train_pos  = ng_sample.read_feather(pathlib.Path(cfg.path.root, cfg.file.train_pos))\n",
    "    df_train_neg = pd.read_feather(pathlib.Path(cfg.path.root, cfg.file.train_neg))\n",
    "    df_test_ori = pd.read_feather(pathlib.Path(cfg.path.root, cfg.file.test)).iloc[:202,]\n",
    "    df_all_features = pd.read_csv(pathlib.Path(cfg.path.root, cfg.file.all_features))\n",
    "    df_train_pos = df_train_pos.sort_values(by=[DEFAULT_USER_COL]).iloc[:100,].reset_index(drop=True)\n",
    "    df_train_neg = df_train_neg.sort_values(by=[DEFAULT_USER_COL]).iloc[:100*cfg.params.neg_train,].reset_index(drop=True)\n",
    "else:\n",
    "    use_amp=True\n",
    "    df_train_pos  = ng_sample.read_feather(pathlib.Path(cfg.path.root, cfg.file.train_pos))\n",
    "    df_train_neg = pd.read_feather(pathlib.Path(cfg.path.root, cfg.file.train_neg))\n",
    "    df_test_ori = pd.read_feather(pathlib.Path(cfg.path.root, cfg.file.test))\n",
    "    df_all_features = pd.read_csv(pathlib.Path(cfg.path.root, cfg.file.all_features))\n",
    "    df_train_pos = df_train_pos.sort_values(by=[DEFAULT_USER_COL]).reset_index(drop=True)\n",
    "    df_train_neg = df_train_neg.sort_values(by=[DEFAULT_USER_COL]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97918f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pos[DEFAULT_RATING_COL] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9b8c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_index(df1, df2):\n",
    "    df2.index = df2.index//cfg.params.neg_train\n",
    "    return pd.concat([df1, df2], axis=0).sort_index(kind='mregesort').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "103e06ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all = concat_index(df_train_pos, df_train_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9255ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all['flag'] = 1\n",
    "df_test_ori['flag'] = 0\n",
    "df_all = pd.concat([df_train_all, df_test_ori], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bc6348",
   "metadata": {},
   "source": [
    "user features: \n",
    "       'WindowID_user', 'Split', 'City',\n",
    "       'State', 'Country', 'Zip_user', 'DegreeType', 'Major', 'GraduationDate',\n",
    "       'WorkHistoryCount', 'TotalYearsExperience', 'CurrentlyEmployed',\n",
    "       'ManagedOthers', 'ManagedHowMany',\n",
    "       \n",
    "job features: \n",
    "       'WindowID_job', 'City_job',\n",
    "       'State_job', 'Country_job', 'Zip_job', 'StartDate', 'EndDate',"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f2bc8",
   "metadata": {},
   "source": [
    "## Sbert embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c894124",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title_emb = pd.read_feather(pathlib.Path(cfg.path.root, cfg.file.title_emb))\n",
    "\n",
    "le_item = preprocessing.LabelEncoder()\n",
    "\n",
    "item_encode_array = le_item.fit_transform(job_title_emb['item_id'].astype('category').cat.codes.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26efb063",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_em_weight = torch.FloatTensor(np.array(job_title_emb.Title_em.tolist()))\n",
    "# title_em_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0715af10",
   "metadata": {},
   "source": [
    "### Choose the features and process data for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "939ed0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userid', 'itemid', 'rating', 'flag'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23a67e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = []\n",
    "user_features_extend = [DEFAULT_USER_COL] + user_features\n",
    "\n",
    "item_features = []\n",
    "item_features_extend =[DEFAULT_ITEM_COL] + item_features\n",
    "\n",
    "base_features = [DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0be3c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mix_merge = mix_merge(df_all , df_all_features, user_features_extend, item_features_extend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8084733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cat_encode(df_data, list_f, encoder):\n",
    "    for f in list_f:\n",
    "        if f==DEFAULT_ITEM_COL:\n",
    "            try:\n",
    "                df_data[f] = le_item.transform(df_data[f].astype('category').cat.codes.values)\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            df_data[f] = encoder.fit_transform(df_data[f].astype('category').cat.codes.values)\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f75839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _embedding_dimension(df_all_encode, features_to_train, max_dim=50):\n",
    "\n",
    "    embedding_size = []\n",
    "    features_to_em = [i for i in features_to_train if i !=DEFAULT_RATING_COL]\n",
    "    for c in features_to_em:\n",
    "        num_unique_values = int(df_all_encode[c].nunique())\n",
    "        embed_dim = int(min(np.ceil(num_unique_values/2), max_dim))\n",
    "        embedding_size.append([num_unique_values, embed_dim])  \n",
    "    return embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a26ae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(df_mix_merge, features_to_code, features_to_train, max_dim=50):\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    df_all_encode = _cat_encode(df_mix_merge, features_to_code, encoder)\n",
    "    df_train = df_all_encode[df_all.flag==1]\n",
    "    df_test = df_all_encode[df_all.flag==0]\n",
    "    df_train = df_train[features_to_train]\n",
    "    df_test = df_test[features_to_train]\n",
    "    embedding_size = _embedding_dimension(df_all_encode, features_to_train, max_dim)\n",
    "    return df_train, df_test, embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6eb03d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feature=[]\n",
    "features_to_code = df_mix_merge.columns\n",
    "features_to_train = [DEFAULT_USER_COL, DEFAULT_ITEM_COL]+ user_features + item_features +[DEFAULT_RATING_COL]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9370037a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of embedding layers:[[36, 18], [413, 50]]\n"
     ]
    }
   ],
   "source": [
    "df_train,  df_test, embedding_size = encode_data(df_mix_merge, features_to_code, features_to_train, max_dim=cfg.params.emb_dim)\n",
    "\n",
    "print(f'The size of embedding layers:{embedding_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff86395",
   "metadata": {},
   "source": [
    "## Run data check before training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7e8d7b",
   "metadata": {},
   "source": [
    "Check the ratio of positive and negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e951d85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df_train[df_train.rating==0])/len(df_train[df_train.rating==1]) == cfg.params.neg_train, 'wrong neg/pos ratio in training set'\n",
    "assert len(df_test[df_test.rating==0])/len(df_test[df_test.rating==1]) == cfg.params.neg_test, 'wrong neg/pos ratio in test set '\n",
    "#Check if all the users in test can be found in training set\n",
    "assert sum(np.isin(df_test.userid.unique(), df_train.userid.unique(), assume_unique=True)) == len(df_test.userid.unique()), 'cold start'\n",
    "#The the uniqueness of items between training and test. For a user, on common items between training and test dataset. \n",
    "assert df_all.shape[0] ==df_train.shape[0]+df_test.shape[0], 'wrong data concat'\n",
    "assert sum(df_all.groupby(['userid']).apply(lambda x: len(x['itemid'].unique()))) == df_all.shape[0], 'train and test have overlap item'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef1f16a",
   "metadata": {},
   "source": [
    "## Creat the numpy array for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98032331",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_split, df_val_split = data_split_user(df_train, val_size=0.2)\n",
    "\n",
    "np_train = df_train_split.values\n",
    "np_val = df_val_split.values\n",
    "np_test = df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fb2a567",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fefad9be310>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb16f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CatData(np_train)\n",
    "val_dataset = CatData(np_val)\n",
    "test_dataset = CatData(np_test) \n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0,  worker_init_fn=seed_worker,generator=g)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False, num_workers=0,  worker_init_fn=seed_worker,generator=g)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=cfg.params.neg_test+1, shuffle=False, num_workers=0,worker_init_fn=seed_worker,generator=g )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8694e807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EntityCat_sbert(\n",
       "  (all_embeddings): ModuleList(\n",
       "    (0): Embedding(36, 18)\n",
       "    (1): Embedding(413, 50)\n",
       "  )\n",
       "  (sbert_embeddings): Embedding(139291, 768)\n",
       "  (mlp_layers): Sequential(\n",
       "    (0): Linear(in_features=836, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "  )\n",
       "  (predict_layer): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EntityCat_sbert(embedding_size = embedding_size, num_numerical_cols = len(num_feature), \\\n",
    "               output_size = 1, word_weight=title_em_weight, encode_array=item_encode_array,\n",
    "                 neurons_in_layers=[100], p=0.4)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7098e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg.params.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686edeec",
   "metadata": {},
   "source": [
    "## Model the training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9670b731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_trans_loss(output):\n",
    "    return output['y_pred'], output['label']\n",
    "\n",
    "val_metrics_train = {\n",
    "    'auc': CustomAuc(),\n",
    "    \"loss\": Loss(criterion, output_transform=output_trans_loss)\n",
    "}\n",
    "\n",
    "val_metrics_test = {\n",
    "    'hr': CustomHR(),\n",
    "    'ndcg': CustomNDCG(k=cfg.params.topk),\n",
    "    'auc': CustomAuc(),\n",
    "    'auc_top': CustomAuc_top(),\n",
    "    'recall_top': CustomRecall_top(k=cfg.params.topk),\n",
    "    'precision_top': CustomPrecision_top(k=cfg.params.topk),\n",
    "    \"loss\": Loss(criterion, output_transform=output_trans_loss)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df93a20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ignite.engine.events.RemovableEventHandle at 0x7feec2d30160>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "def train_step(engine, batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch[0].to(device), batch[1].to(device)\n",
    "    with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "        y_pred = model(x).reshape(1,-1).flatten()\n",
    "        loss = criterion(y_pred, y.float())\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    return loss.item()\n",
    "\n",
    "def validation_step(engine, batch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, label = batch[0].to(device), batch[1].to(device)\n",
    "        y_pred = model(x).reshape(1,-1).flatten()\n",
    "        label=label.float()\n",
    "        return {'label':label, 'y_pred':y_pred}\n",
    "\n",
    "def test_step(engine, batch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, label = batch[0].to(device), batch[1].to(device)\n",
    "        y_pred = model(x).reshape(1,-1).flatten()\n",
    "        label=label.float()\n",
    "        \n",
    "        y_pred_top, indices = torch.topk(y_pred, engine.state.topk)\n",
    "        \n",
    "        y_pred_top = y_pred_top.detach().cpu().numpy()\n",
    "        reco_item = torch.take(x[:,1], indices).cpu().numpy().tolist()\n",
    "        pos_item = x[0,1].cpu().numpy().tolist()  # ground truth, item id\n",
    "        label_top = label[indices].cpu().numpy()\n",
    "        indices = indices.cpu().numpy()\n",
    "        return {'pos_item':pos_item, 'reco_item':reco_item, 'y_pred_top':y_pred_top, \n",
    "                'label_top':label_top, 'label':label, 'y_pred':y_pred, 'y_indices':indices}\n",
    "    \n",
    "trainer = Engine(train_step)\n",
    "\n",
    "train_evaluator = Engine(validation_step)\n",
    "# train_evaluator.state_dict_user_keys.append('topk')\n",
    "\n",
    "val_evaluator = Engine(validation_step)\n",
    "# val_evaluator.state_dict_user_keys.append('topk')\n",
    "\n",
    "test_evaluator = Engine(test_step)\n",
    "test_evaluator.state_dict_user_keys.append('topk')\n",
    "\n",
    "# @val_evaluator.on(Events.STARTED)\n",
    "# def init_user_value():\n",
    "#     val_evaluator.state.topk=3\n",
    "    \n",
    "# @train_evaluator.on(Events.STARTED)\n",
    "# def init_user_value():\n",
    "#     train_evaluator.state.topk=3\n",
    "\n",
    "@train_evaluator.on(Events.STARTED)\n",
    "def init_user_value():\n",
    "    test_evaluator.state.topk=cfg.params.topk\n",
    "    \n",
    "    \n",
    "# Attach metrics to the evaluators\n",
    "for name, metric in val_metrics_train.items():\n",
    "    metric.attach(train_evaluator, name)\n",
    "\n",
    "for name, metric in val_metrics_train.items():\n",
    "    metric.attach(val_evaluator, name)\n",
    "\n",
    "    \n",
    "for name, metric in val_metrics_test.items():\n",
    "    metric.attach(test_evaluator, name)\n",
    "    \n",
    "# Eearly_stop \n",
    "def score_function(engine):\n",
    "    val_loss = engine.state.metrics['auc']\n",
    "    return val_loss\n",
    "\n",
    "Eearly_stop_handler = EarlyStopping(patience=cfg.params.patience, score_function=score_function, trainer=trainer)\n",
    "val_evaluator.add_event_handler(Events.COMPLETED, Eearly_stop_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b9d6ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    train_evaluator.run(train_loader)\n",
    "    metrics = train_evaluator.state.metrics\n",
    "    auc = metrics['auc']\n",
    "    loss = metrics['loss']\n",
    "    print(f'Training Results- Epoch[{trainer.state.epoch}]  Avg loss: {loss:.2f} \\\n",
    "          Avg auc:{auc:.2f}')\n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    val_evaluator.run(val_loader)\n",
    "    metrics = val_evaluator.state.metrics\n",
    "    auc = metrics['auc']\n",
    "    loss = metrics['loss']\n",
    "    print(f'Validation Results- Epoch[{trainer.state.epoch}]  Avg loss: {loss:.2f} \\\n",
    "          Avg auc:{auc:.2f}')\n",
    "\n",
    "    \n",
    "@trainer.on(Events.COMPLETED)\n",
    "def log_test_results(trainer):\n",
    "    test_evaluator.run(test_loader)\n",
    "    metrics = test_evaluator.state.metrics\n",
    "    hr = metrics['hr']\n",
    "    ndcg = metrics['ndcg']\n",
    "    auc = metrics['auc']\n",
    "    auc_top = metrics['auc_top']\n",
    "    recall = metrics['recall_top']\n",
    "    precision = metrics['precision_top']\n",
    "    loss = metrics['loss']\n",
    "    print(f\"Test Results - Epoch[{trainer.state.epoch}]  Avg loss: {loss:.2f} \\\n",
    "     Avg ndcg: {ndcg:.2f}  Avg auc: {auc:.2f}  Avg auc_top: {auc_top:.2f} \\\n",
    "      Avg recall: {recall:.2f}  Avg precision: {precision:.2f}\")\n",
    "\n",
    "pbar = ProgressBar(persist=False)\n",
    "# pbar.attach(trainer)\n",
    "pbar.attach(trainer)\n",
    "# from ignite.handlers import Timer\n",
    "# timer = Timer(average=True)\n",
    "# timer.attach(trainer,\n",
    "#              start=Events.STARTED,\n",
    "#              resume=Events.EPOCH_STARTED,\n",
    "#              pause=Events.EPOCH_COMPLETED,\n",
    "#              step=Events.EPOCH_COMPLETED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af997b32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current run is terminating due to exception: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)\n",
      "Engine run is terminating due to exception: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:704\u001b[0m, in \u001b[0;36mEngine.run\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch_length should be provided if data is None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m--> 704\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:783\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 783\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:466\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:753\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_engine()\n\u001b[0;32m--> 753\u001b[0m time_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once_on_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;66;03m# time is available for handlers but must be update after fire\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimes[Events\u001b[38;5;241m.\u001b[39mEPOCH_COMPLETED\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m time_taken\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:854\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 854\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:466\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:840\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39miteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_STARTED)\n\u001b[0;32m--> 840\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_COMPLETED)\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_terminate \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_terminate_single_epoch:\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m      5\u001b[0m x, y \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), batch[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39muse_amp):\n\u001b[0;32m----> 7\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(y_pred, y\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m      9\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/MA_thesis_u/ncf-torch2/src/jupyter/../../src/model_entity.py:129\u001b[0m, in \u001b[0;36mEntityCat_sbert.forward\u001b[0;34m(self, x_categorical)\u001b[0m\n\u001b[1;32m    127\u001b[0m     to_cat\u001b[38;5;241m.\u001b[39mappend(emb_layer(x_categorical[:, col_index]))\n\u001b[1;32m    128\u001b[0m item_index_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_item_index(x_categorical)\n\u001b[0;32m--> 129\u001b[0m to_cat\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msbert_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem_index_tensor\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    130\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(to_cat, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    131\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_layers(x)\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/torch/nn/modules/sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/torch/nn/functional.py:2183\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2177\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2178\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2179\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2180\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2181\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2182\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)"
     ]
    }
   ],
   "source": [
    "trainer.run(train_loader, max_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b18f030d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.19"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hao/Documents/MA_thesis_u/ncf-torch2/src/jupyter/wandb/run-20220715_083712-zgjyxew3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/tiyuok2023/pytorch-jrs/runs/zgjyxew3\" target=\"_blank\">-</a></strong> to <a href=\"https://wandb.ai/tiyuok2023/pytorch-jrs\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:703: indexSelectLargeIndex: block: [2,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "Current run is terminating due to exception: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Engine run is terminating due to exception: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m wandb_logger\u001b[38;5;241m.\u001b[39mattach_opt_params_handler(\n\u001b[1;32m     55\u001b[0m     trainer,\n\u001b[1;32m     56\u001b[0m     event_name\u001b[38;5;241m=\u001b[39mEvents\u001b[38;5;241m.\u001b[39mITERATION_STARTED,\n\u001b[1;32m     57\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m     58\u001b[0m     param_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# optional\u001b[39;00m\n\u001b[1;32m     59\u001b[0m )\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# wandb_logger.watch(model) \u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m wandb_logger\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:704\u001b[0m, in \u001b[0;36mEngine.run\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch_length should be provided if data is None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m--> 704\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:783\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 783\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:466\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:753\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_engine()\n\u001b[0;32m--> 753\u001b[0m time_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once_on_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;66;03m# time is available for handlers but must be update after fire\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimes[Events\u001b[38;5;241m.\u001b[39mEPOCH_COMPLETED\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m time_taken\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:854\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 854\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:466\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/ignite/engine/engine.py:840\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39miteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_STARTED)\n\u001b[0;32m--> 840\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_COMPLETED)\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_terminate \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_terminate_single_epoch:\n",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m      5\u001b[0m x, y \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), batch[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39muse_amp):\n\u001b[0;32m----> 7\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(y_pred, y\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m      9\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/virtualenvs/ncf-torch-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/MA_thesis_u/ncf-torch2/src/jupyter/../../src/model_entity.py:128\u001b[0m, in \u001b[0;36mEntityCat_sbert.forward\u001b[0;34m(self, x_categorical)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col_index, emb_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_embeddings):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;66;03m# print('hao----', emb_layer.weight.grad)\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     to_cat\u001b[38;5;241m.\u001b[39mappend(emb_layer(x_categorical[:, col_index]))\n\u001b[0;32m--> 128\u001b[0m item_index_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_item_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_categorical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m to_cat\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msbert_embeddings(item_index_tensor))\n\u001b[1;32m    130\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(to_cat, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/MA_thesis_u/ncf-torch2/src/jupyter/../../src/model_entity.py:115\u001b[0m, in \u001b[0;36mEntityCat_sbert._item_index\u001b[0;34m(self, x_categorical)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_item_index\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_categorical):\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    The the index from the item enecoder array\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     itemids \u001b[38;5;241m=\u001b[39m \u001b[43mx_categorical\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    116\u001b[0m     item_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msorter[np\u001b[38;5;241m.\u001b[39msearchsorted(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_array, itemids, sorter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msorter)]\n\u001b[1;32m    117\u001b[0m     item_index_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor(item_index)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "config_dict = dict(cfg.params)\n",
    "config_dict['Features']='-'.join(user_features+item_features)\n",
    "wandb_logger = WandBLogger(\n",
    "    project=\"pytorch-jrs\",\n",
    "    name=\"-\".join(user_features)+'-'+'-'.join(item_features),\n",
    "    config=config_dict,\n",
    "    tags=[\"entity\", \"jrs\", \"nlp\"]\n",
    ")\n",
    "\n",
    "to_save = {'model': model}\n",
    "checkpoint_handler = ModelCheckpoint(\n",
    "    wandb_logger.run.dir,\n",
    "    n_saved=1, filename_prefix='best',\n",
    "    score_name=\"auc\",\n",
    "    global_step_transform=global_step_from_engine(trainer)\n",
    ")\n",
    "\n",
    "val_evaluator.add_event_handler(Events.COMPLETED, checkpoint_handler, to_save)\n",
    "\n",
    "    \n",
    "wandb_logger.attach_output_handler(\n",
    "    trainer,\n",
    "    event_name=Events.ITERATION_COMPLETED,\n",
    "    tag=\"training\",\n",
    "    output_transform=lambda loss: {\"loss\": loss}\n",
    ")\n",
    "\n",
    "wandb_logger.attach_output_handler(\n",
    "    train_evaluator,\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    "    tag=\"training\",\n",
    "    metric_names=['loss','auc'],\n",
    "    global_step_transform=lambda *_: trainer.state.iteration,\n",
    ")\n",
    "\n",
    "wandb_logger.attach_output_handler(\n",
    "    val_evaluator,\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    "    tag=\"validation\",\n",
    "    metric_names=['loss',\"auc\"],\n",
    "    global_step_transform=lambda *_: trainer.state.iteration,\n",
    ")\n",
    "\n",
    "\n",
    "wandb_logger.attach_output_handler(\n",
    "    test_evaluator,\n",
    "    event_name=Events.COMPLETED,\n",
    "    tag=\"test\",\n",
    "    metric_names=['loss',\"auc\", 'hr', 'ndcg', 'auc_top', 'recall_top', 'precision_top'],\n",
    "    global_step_transform=lambda *_: trainer.state.iteration,\n",
    ")\n",
    "\n",
    "\n",
    "wandb_logger.attach_opt_params_handler(\n",
    "    trainer,\n",
    "    event_name=Events.ITERATION_STARTED,\n",
    "    optimizer=optimizer,\n",
    "    param_name='lr'  # optional\n",
    ")\n",
    "\n",
    "# wandb_logger.watch(model) \n",
    "\n",
    "trainer.run(train_loader, max_epochs=EPOCHS)\n",
    "wandb_logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea211e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c02e1ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
