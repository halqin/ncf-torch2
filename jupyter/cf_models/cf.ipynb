{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ee1b655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%aimport -torch, pandas, hydra, numpy, pickle, os\n",
    "# %aimport src, src.metrics\n",
    "%autoreload 2\n",
    "import os\n",
    "from hydra import initialize, compose\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# from datasets.jobdataset import generate_dataset, _hfd5_from_dataframe\n",
    "from src.data_process.job_hdf5 import hdf5_from_dataframe, get_career\n",
    "import src.data_process.neg_sample as ng_sample\n",
    "from src.utils.constants import DEFAULT_USER_COL,DEFAULT_ITEM_COL,DEFAULT_RATING_COL, DEFAULT_PREDICTION_COL\n",
    "# from implicit_eval import microsoft_eval,model_infer_df\n",
    "# from implicit.als import AlternatingLeastSquares\n",
    "# from implicit.bpr import BayesianPersonalizedRanking\n",
    "# from implicit.lmf import LogisticMatrixFactorization\n",
    "from src.implicit_build import bpr, bpr, lmf\n",
    "from src.metrics import ranking\n",
    "from src.metrics.evaluate_ignite import model_infer2\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../../src/conf\"):\n",
    "    cfg = compose(config_name=\"config\", overrides=['path.root=../../data/jobs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9f2e52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtiyuok2023\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "059ae5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "all-except-skipped\n",
      "\n",
      "Modules to skip:\n",
      "torch, pandas, hydra, numpy, pickle, os\n"
     ]
    }
   ],
   "source": [
    "%aimport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76593aa6",
   "metadata": {},
   "source": [
    "# Create the the data pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1dd920d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pos  = ng_sample.read_feather(pathlib.Path(cfg.path.root, cfg.file.train_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dff7b576",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pos[DEFAULT_RATING_COL] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f95dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_pos[DEFAULT_USER_COL] = df_train_pos[DEFAULT_USER_COL].astype(str)\n",
    "# df_train_pos[DEFAULT_ITEM_COL] = df_train_pos[DEFAULT_ITEM_COL].astype(str)\n",
    "df_train_pos[DEFAULT_USER_COL] = df_train_pos[DEFAULT_USER_COL].astype(\"category\")\n",
    "df_train_pos[DEFAULT_ITEM_COL] = df_train_pos[DEFAULT_ITEM_COL].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86adffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdf5_from_dataframe(df_train_pos, pathlib.Path(cfg.path.root, cfg.file.hdf5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f29f47",
   "metadata": {},
   "source": [
    "## Read data & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d46bdf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobsid, usersid, user_job_app = get_career(pathlib.Path(cfg.path.leave_one_cf, cfg.leave_one_data.hdf5))\n",
    "model_path = \"./models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "545afd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_job_app = job_user_app.T.tocsr()\n",
    "# bpr(model_path, user_job_app)\n",
    "# als(model_path, user_job_app)\n",
    "# lmf(model_path, user_job_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83036205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_gd_csv(data_testgd_path, usecols):\n",
    "    test_gddf = pd.read_csv(data_testgd_path, usecols=usecols)\n",
    "#     test_gddf[DEFAULT_USER_COL] = test_gddf[DEFAULT_USER_COL].astype('str')\n",
    "#     test_gddf[DEFAULT_ITEM_COL] = test_gddf[DEFAULT_ITEM_COL].astype('str')\n",
    "    return test_gddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba437309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_ori = pd.read_feather(pathlib.Path(cfg.path.leave_one_cf, cfg.leave_one_data.test_pos_neg))\n",
    "# df_train =read_train_gd_csv('../../data/jobs/leave_one_train_neg.csv', usecols=[DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL])\n",
    "# df_test =read_train_gd_csv('../../data/jobs/leave_one_test.csv', usecols=[DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20ae4f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./models/model_als.sav','rb') as pickle_in:\n",
    "    model_als = pickle.load(pickle_in)\n",
    "with open('./models/model_bpr.sav','rb') as pickle_in:\n",
    "    model_bpr = pickle.load(pickle_in)\n",
    "with open('./models/model_lmf.sav','rb') as pickle_in:\n",
    "    model_lmf = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76068022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_metrics(apps_true, jobsid, usersid,model, u_i_matrix, n, metric:dict):\n",
    "    gt_item, reco_ind, pd_scores = model_infer2(df_true=apps_true, jobsid=jobsid, usersid=usersid, \n",
    "                                 model=model, u_i_matrix=user_job_app, n=cfg.params.neg_test+1) \n",
    "    precision = metric['precision'].compute(gt_pos=gt_item, pd_rank=reco_ind)\n",
    "    recall = metric['recall'].compute(gt_pos=gt_item, pd_rank=reco_ind)\n",
    "    ndcg = metric['ndcg'].compute(gt_pos=gt_item, pd_rank=reco_ind)\n",
    "    auc_k = metric['auc_k'].compute(gt_pos=gt_item, pd_scores=pd_scores, pd_rank=reco_ind)\n",
    "    auc = metric['auc'].compute(gt_pos=gt_item, pd_scores=pd_scores)\n",
    "    hit = metric['hit'].compute(gt_pos=gt_item, pd_rank=reco_ind)\n",
    "    map_k = metric['map_k'].compute(gt_pos=gt_item, pd_scores=pd_scores, pd_rank=reco_ind)\n",
    "    \n",
    "    return [precision, recall, ndcg, auc_k, auc, hit, map_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6b7661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(metric_value, wandb_enable: False, model_name:str, project_name:str)->dict:\n",
    "    precision_top = np.mean(np.array(list(metric_value.flat))[:,0])\n",
    "    recall_top = np.mean(np.array(list(metric_value.flat))[:,1])\n",
    "    ndcg_top = np.mean(np.array(list(metric_value.flat))[:,2])\n",
    "    auc_top_k = np.mean(np.array(list(metric_value.flat))[:,3])\n",
    "    auc = np.mean(np.array(list(metric_value.flat))[:,4])\n",
    "    hit = np.mean(np.array(list(metric_value.flat))[:,5])\n",
    "    map_k = np.mean(np.array(list(metric_value.flat))[:,6])\n",
    "    print(f'Precision: {precision_top:.4f} \\nRecall: {recall_top:.4f} \\nNDCG: {ndcg_top:.4f} \\nAUC_K: {auc_top_k:.4f} \\\n",
    "    \\nAUC: {auc:.4f} \\nHitRate: {hit:.4f} \\nMAP_K: {map_k:.4f}')\n",
    "    result_dict = {'Precision': precision_top, 'Recall': recall_top, 'NDCG': ndcg_top, 'AUC_K':auc_top_k, 'AUC':auc,\\\n",
    "                   'HitRate':hit, 'MAP_K':map_k}\n",
    "    if wandb:\n",
    "        wandb_log(model_name, project_name, result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da48c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandb_log(model_name:str, project_name:str, result:dict):\n",
    "    wandb.init(project=project_name,\n",
    "          name = model_name,\n",
    "           tags= ['jrs','cf'],\n",
    "           config = dict(cfg.params)\n",
    "          )\n",
    "    wandb.log(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6982c12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_true = df_test_ori[df_test_ori['userid'].isin([1472090])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed9f5302",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "k=cfg.params.topk\n",
    "metric={'precision':ranking.Precision(k=k),'recall':ranking.Recall(k=k), 'ndcg':ranking.NDCG(k=k), \\\n",
    "        'auc_k':ranking.AUC_K(k=k),'auc':ranking.AUC(), 'hit':ranking.HitRate(k=k), 'map_k':ranking.MAP_K(k=k)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64b6a6ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0916bdceb947b7b160b0a3fcededd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric_result = apps_true.groupby('userid').progress_apply(cal_metrics, jobsid=jobsid, usersid=usersid, \n",
    "                            model=model_bpr, u_i_matrix=user_job_app, \n",
    "                           n=cfg.params.neg_test+1, metric=metric)\n",
    "metric_value_b = metric_result.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30936364",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.1000 \n",
      "Recall: 1.0000 \n",
      "NDCG: 0.3010 \n",
      "AUC_K: 0.1111     \n",
      "AUC: 0.9048 \n",
      "HitRate: 1.0000 \n",
      "MAP_K: 0.1111\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.19"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/hao/Documents/MA_thesis/ncf-torch2/jupyter/cf_models/wandb/run-20220726_000022-7u5eb3ut</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/tiyuok2023/my-cf-project/runs/7u5eb3ut\" target=\"_blank\">bpr</a></strong> to <a href=\"https://wandb.ai/tiyuok2023/my-cf-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "restult_dict = get_results(metric_value_b, wandb_enable=True,model_name='bpr', project_name=cfg.name.cf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f88c938",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74091/74091 [09:27<00:00, 130.64it/s]\n"
     ]
    }
   ],
   "source": [
    "metric_result = df_test_ori.groupby('userid').progress_apply(cal_metrics, jobsid=jobsid, usersid=usersid, \n",
    "                            model=model_als, u_i_matrix=user_job_app, \n",
    "                           n=cfg.params.neg_test+1, metric=metric)\n",
    "metric_value_a = metric_result.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "573f1909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0848 \n",
      "Recall: 0.8477 \n",
      "NDCG: 0.7233 \n",
      "AUC_K: 0.7690     \n",
      "AUC: 0.9213 \n",
      "HitRate: 0.8477\n"
     ]
    }
   ],
   "source": [
    "restult_dict = get_results(metric_value_b, wandb_enable=True,model_name='als', project_name=cfg.name.cf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d540e969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74091/74091 [09:00<00:00, 137.11it/s]\n"
     ]
    }
   ],
   "source": [
    "metric_result = df_test_ori.groupby('userid').progress_apply(cal_metrics, jobsid=jobsid, usersid=usersid, \n",
    "                            model=model_lmf, u_i_matrix=user_job_app, \n",
    "                           n=cfg.params.neg_test+1, metric=metric)\n",
    "metric_value_l = metric_result.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7b2a68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0786 \n",
      "Recall: 0.7861 \n",
      "NDCG: 0.6728 \n",
      "AUC_K: 0.7111     \n",
      "AUC: 0.8925 \n",
      "HitRate: 0.7861\n"
     ]
    }
   ],
   "source": [
    "restult_dict = get_results(metric_value_b, wandb_enable=True,model_name='lmf', project_name=cfg.name.cf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083229aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision: 0.0786 \n",
    "Recall: 0.7861 \n",
    "NDCG: 0.6728 \n",
    "AUC_K: 0.7111     \n",
    "AUC: 0.8925 \n",
    "HitRate: 0.1283"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
