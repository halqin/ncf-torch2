{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d3cbac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hao/.pyenv/versions/3.6.15/envs/torch-cpu5/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1082f1198>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../src')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "from hydra import initialize, compose\n",
    "import pathlib\n",
    "# import config\n",
    "\n",
    "import data_process.neg_sample as ng_sample\n",
    "from data_process.utils import mix_merge\n",
    "from data_process.data_split import data_split_user\n",
    "from metrics.evaluate_ignite import CustomHR, CustomNDCG, CustomAuc_top, CustomAuc, CustomRecall_top, CustomPrecision_top\n",
    "from model_entity import EntityCat\n",
    "from data_utils import CatData\n",
    "from utils.constants import DEFAULT_USER_COL,DEFAULT_ITEM_COL,DEFAULT_RATING_COL, DEFAULT_TIMESTAMP_COL\n",
    "from metrics import ranking\n",
    "\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, recall_score, precision_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# import argparse\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "452234bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Engine, Events, create_supervised_trainer, create_supervised_evaluator, RemovableEventHandle\n",
    "from ignite.metrics import Accuracy, Loss, Metric\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "from ignite.exceptions import NotComputableError\n",
    "from ignite.metrics.metric import sync_all_reduce, reinit__is_reduced\n",
    "from ignite.contrib.handlers.tqdm_logger import ProgressBar\n",
    "# from ignite.contrib.handlers import TensorboardLogger \n",
    "from ignite.contrib.handlers.wandb_logger import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c9d49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c783c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path=\"../conf\"):\n",
    "    cfg = compose(config_name=\"config\", overrides=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3fca5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type =='cpu':\n",
    "    BATCH_SIZE = cfg.params.batch_size_cpu\n",
    "    EPOCHS  = cfg.params.epochs_cpu\n",
    "else:\n",
    "    BATCH_SIZE = cfg.params.batch_size_gpu\n",
    "    EPOCHS  = cfg.params.epochs_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e094616",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type == 'cpu':\n",
    "    use_amp=False\n",
    "    df_train_pos  = ng_sample.read_feather(pathlib.Path(cfg.path.root, cfg.file.train_pos))\n",
    "    df_train_neg = pd.read_feather(pathlib.Path(cfg.path.root, cfg.file.train_neg))\n",
    "    df_test_ori = pd.read_feather(pathlib.Path(cfg.path.root, cfg.file.test)).iloc[:202,]\n",
    "    df_all_features = pd.read_csv(pathlib.Path(cfg.path.root, cfg.file.all_features))\n",
    "    df_train_pos = df_train_pos.sort_values(by=[DEFAULT_USER_COL]).iloc[:100,].reset_index(drop=True)\n",
    "    df_train_neg = df_train_neg.sort_values(by=[DEFAULT_USER_COL]).iloc[:100*cfg.params.neg_train,].reset_index(drop=True)\n",
    "else:\n",
    "    use_amp=True\n",
    "    df_train_pos  = ng_sample.read_feather(pathlib.Path(cfg.path.root, cfg.file.train_pos))\n",
    "    df_train_neg = pd.read_feather(pathlib.Path(cfg.path.root, cfg.file.train_neg))\n",
    "    df_test_ori = pd.read_feather(pathlib.Path(cfg.path.root, cfg.file.test))\n",
    "    df_all_features = pd.read_csv(pathlib.Path(cfg.path.root, cfg.file.all_features))\n",
    "    df_train_pos = df_train_pos.sort_values(by=[DEFAULT_USER_COL]).reset_index(drop=True)\n",
    "    df_train_neg = df_train_neg.sort_values(by=[DEFAULT_USER_COL]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97918f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pos[DEFAULT_RATING_COL] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9b8c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_index(df1, df2):\n",
    "    df2.index = df2.index//cfg.params.neg_train\n",
    "    return pd.concat([df1, df2], axis=0).sort_index(kind='mregesort').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "103e06ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all = concat_index(df_train_pos, df_train_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9255ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all['flag'] = 1\n",
    "df_test_ori['flag'] = 0\n",
    "df_all = pd.concat([df_train_all, df_test_ori], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bc6348",
   "metadata": {},
   "source": [
    "user features: \n",
    "       'WindowID_user', 'Split', 'City',\n",
    "       'State', 'Country', 'Zip_user', 'DegreeType', 'Major', 'GraduationDate',\n",
    "       'WorkHistoryCount', 'TotalYearsExperience', 'CurrentlyEmployed',\n",
    "       'ManagedOthers', 'ManagedHowMany',\n",
    "       \n",
    "job features: \n",
    "       'WindowID_job', 'City_job',\n",
    "       'State_job', 'Country_job', 'Zip_job', 'StartDate', 'EndDate',"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0715af10",
   "metadata": {},
   "source": [
    "### Choose the features and process data for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "939ed0e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userid', 'itemid', 'rating', 'flag'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23a67e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = []\n",
    "user_features_extend = [DEFAULT_USER_COL] + user_features\n",
    "\n",
    "item_features = []\n",
    "item_features_extend =[DEFAULT_ITEM_COL] + item_features\n",
    "\n",
    "base_features = [DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0be3c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mix_merge = mix_merge(df_all , df_all_features, user_features_extend, item_features_extend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8084733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cat_encode(df_data, list_f, encoder):\n",
    "    for f in list_f:\n",
    "        df_data[f] = encoder.fit_transform(df_data[f].astype('category').cat.codes.values)\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f75839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _embedding_dimension(df_all_encode, features_to_train, max_dim=50):\n",
    "\n",
    "    embedding_size = []\n",
    "    features_to_em = [i for i in features_to_train if i !=DEFAULT_RATING_COL]\n",
    "    for c in features_to_em:\n",
    "        num_unique_values = int(df_all_encode[c].nunique())\n",
    "        embed_dim = int(min(np.ceil(num_unique_values/2), max_dim))\n",
    "        embedding_size.append([num_unique_values, embed_dim])  \n",
    "    return embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a26ae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(df_mix_merge, features_to_code, features_to_train, max_dim=50):\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    df_all_encode = _cat_encode(df_mix_merge, features_to_code, encoder)\n",
    "    df_train = df_all_encode[df_all.flag==1]\n",
    "    df_test = df_all_encode[df_all.flag==0]\n",
    "    df_train = df_train[features_to_train]\n",
    "    df_test = df_test[features_to_train]\n",
    "    embedding_size = _embedding_dimension(df_all_encode, features_to_train, max_dim)\n",
    "    return df_train, df_test, embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6eb03d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feature=[]\n",
    "features_to_code = df_mix_merge.columns\n",
    "features_to_train = [DEFAULT_USER_COL, DEFAULT_ITEM_COL]+ user_features + item_features +[DEFAULT_RATING_COL]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9370037a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of embedding layers:[[36, 18], [413, 50]]\n"
     ]
    }
   ],
   "source": [
    "df_train,  df_test, embedding_size = encode_data(df_mix_merge, features_to_code, features_to_train, max_dim=cfg.params.emb_dim)\n",
    "\n",
    "print(f'The size of embedding layers:{embedding_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097c1796",
   "metadata": {},
   "source": [
    "## Run data check before training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a0908b",
   "metadata": {},
   "source": [
    "Check the ratio of positive and negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f145732",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df_train[df_train.rating==0])/len(df_train[df_train.rating==1]) == cfg.params.neg_train, 'wrong neg/pos ratio in training set'\n",
    "assert len(df_test[df_test.rating==0])/len(df_test[df_test.rating==1]) == cfg.params.neg_test, 'wrong neg/pos ratio in test set '\n",
    "#Check if all the users in test can be found in training set\n",
    "assert sum(np.isin(df_test.userid.unique(), df_train.userid.unique(), assume_unique=True)) == len(df_test.userid.unique()), 'cold start'\n",
    "#The the uniqueness of items between training and test. For a user, on common items between training and test dataset. \n",
    "assert df_all.shape[0] ==df_train.shape[0]+df_test.shape[0], 'wrong data concat'\n",
    "assert sum(df_all.groupby(['userid']).apply(lambda x: len(x['itemid'].unique()))) == df_all.shape[0], 'train and test have overlap item'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10170493",
   "metadata": {},
   "source": [
    "## Creat the numpy array for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98032331",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_split, df_val_split = data_split_user(df_train, val_size=0.2)\n",
    "\n",
    "np_train = df_train_split.values\n",
    "np_val = df_val_split.values\n",
    "np_test = df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fb2a567",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x12fde61c8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb16f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CatData(np_train)\n",
    "val_dataset = CatData(np_val)\n",
    "test_dataset = CatData(np_test) \n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0,  worker_init_fn=seed_worker,generator=g)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False, num_workers=0,  worker_init_fn=seed_worker,generator=g)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=cfg.params.neg_test+1, shuffle=False, num_workers=0,worker_init_fn=seed_worker,generator=g )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8694e807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EntityCat(\n",
       "  (all_embeddings): ModuleList(\n",
       "    (0): Embedding(36, 18)\n",
       "    (1): Embedding(413, 50)\n",
       "  )\n",
       "  (mlp_layers): Sequential(\n",
       "    (0): Linear(in_features=68, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "  )\n",
       "  (predict_layer): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EntityCat(embedding_size = embedding_size, num_numerical_cols = len(num_feature),\n",
    "               output_size = 1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7098e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg.params.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01238764",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save = {'model': model}\n",
    "save_path = '/Users/hao/Documents/MA_thesis/ncf-torch2/src/jupyter/runs/'\n",
    "checkpoint_fp = save_path + \"best_model_16_auc=0.9294.pt\"\n",
    "checkpoint = torch.load(checkpoint_fp, map_location=device) \n",
    "ModelCheckpoint.load_objects(to_load=to_save, checkpoint=checkpoint) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fcba0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1646fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = torch.tensor([.1, .2, .7, .6, .5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90300562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.topk(y_pred, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f07c566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_trans_loss(output):\n",
    "    return output['y_pred'], output['label']\n",
    "\n",
    "val_metrics_test = {\n",
    "    'hr': CustomHR(),\n",
    "    'ndcg': CustomNDCG(k=cfg.params.topk),\n",
    "    'auc': CustomAuc(),\n",
    "    'roc_top': CustomAuc_top(),\n",
    "    'recall_top': CustomRecall_top(k=cfg.params.topk),\n",
    "    'precision_top': CustomPrecision_top(k=cfg.params.topk),\n",
    "    \"loss\": Loss(criterion, output_transform=output_trans_loss)\n",
    "}\n",
    "def test_step(engine, batch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, label = batch[0].to(device), batch[1].to(device)\n",
    "        y_pred = model(x).reshape(1,-1).flatten()\n",
    "        label=label.float()\n",
    "        \n",
    "        y_pred_top, indices = torch.topk(y_pred, engine.state.topk)\n",
    "        \n",
    "        y_pred_top = y_pred_top.detach().cpu().numpy()\n",
    "        reco_item = torch.take(x[:,1], indices).cpu().numpy().tolist()\n",
    "        pos_item = x[0,1].cpu().numpy().tolist()  # ground truth, item id\n",
    "        label_top = label[indices].cpu().numpy()\n",
    "        indices = indices.cpu().numpy()\n",
    "        return {'pos_item':pos_item, 'reco_item':reco_item, 'y_pred_top':y_pred_top, \n",
    "                'label_top':label_top, 'label':label, 'y_pred':y_pred, 'y_indices':indices}\n",
    "\n",
    "    \n",
    "test_evaluator = Engine(test_step)\n",
    "test_evaluator.state_dict_user_keys.append('topk')\n",
    "@test_evaluator.on(Events.STARTED)\n",
    "def init_user_value():\n",
    "    test_evaluator.state.topk=cfg.params.topk\n",
    "    \n",
    "for name, metric in val_metrics_test.items():\n",
    "    metric.attach(test_evaluator, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55e4d653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Avg loss: 0.84  Avg ndcg: 0.00  Avg auc: 0.56  Avg auc_top: 0.00   Avg recall: 0.00  Avg precision: 0.00\n"
     ]
    }
   ],
   "source": [
    "# @trainer.on(Events.COMPLETED)\n",
    "# def log_test_results(trainer):\n",
    "test_evaluator.run(test_loader)\n",
    "metrics = test_evaluator.state.metrics\n",
    "hr = metrics['hr']\n",
    "ndcg = metrics['ndcg']\n",
    "auc = metrics['auc']\n",
    "roc_top = metrics['roc_top']\n",
    "recall = metrics['recall_top']\n",
    "precision = metrics['precision_top']\n",
    "loss = metrics['loss']\n",
    "print(f\"Test Results - Avg loss: {loss:.2f} \\\n",
    " Avg ndcg: {ndcg:.2f}  Avg auc: {auc:.2f}  Avg auc_top: {roc_top:.2f} \\\n",
    "  Avg recall: {recall:.2f}  Avg precision: {precision:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719e6546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebe1256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a12559f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62affde4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49686dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2045a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.15 64-bit ('torch-cpu5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f39b6b9188930cc56c17ea8920a1192f2b927e6749fd92c06f0e66e64aa83d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
